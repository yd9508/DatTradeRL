{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462cafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "# from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b12b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb6ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (88061, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = '2009-01-01',\n",
    "                     end_date = '2021-01-01',\n",
    "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8cc8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88061, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee27f9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.751010</td>\n",
       "      <td>746015200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>43.073929</td>\n",
       "      <td>6547900</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.256275</td>\n",
       "      <td>10955700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941113</td>\n",
       "      <td>7010200</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>31.254059</td>\n",
       "      <td>7117200</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close     volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.751010  746015200  AAPL   \n",
       "1  2009-01-02  58.590000  59.080002  57.750000  43.073929    6547900  AMGN   \n",
       "2  2009-01-02  18.570000  19.520000  18.400000  15.256275   10955700   AXP   \n",
       "3  2009-01-02  42.799999  45.560001  42.779999  33.941113    7010200    BA   \n",
       "4  2009-01-02  44.910000  46.980000  44.709999  31.254059    7117200   CAT   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    4  \n",
       "4    4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ee01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ef11c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.751010</td>\n",
       "      <td>746015200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>43.073929</td>\n",
       "      <td>6547900</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.256275</td>\n",
       "      <td>10955700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941113</td>\n",
       "      <td>7010200</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>31.254059</td>\n",
       "      <td>7117200</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       open       high        low      close     volume   tic  day\n",
       "0 2009-01-02   3.067143   3.251429   3.041429   2.751010  746015200  AAPL    4\n",
       "1 2009-01-02  58.590000  59.080002  57.750000  43.073929    6547900  AMGN    4\n",
       "2 2009-01-02  18.570000  19.520000  18.400000  15.256275   10955700   AXP    4\n",
       "3 2009-01-02  42.799999  45.560001  42.779999  33.941113    7010200    BA    4\n",
       "4 2009-01-02  44.910000  46.980000  44.709999  31.254059    7117200   CAT    4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938f11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/61692356.py:3: DtypeWarning: Columns (16,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fund = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/mariko-sawada/FinRL_with_fundamental_data/main/dow_30_fundamental_wrds.csv'\n",
    "\n",
    "fund = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cdeb012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>fyr</th>\n",
       "      <th>indfmt</th>\n",
       "      <th>consol</th>\n",
       "      <th>popsrc</th>\n",
       "      <th>datafmt</th>\n",
       "      <th>tic</th>\n",
       "      <th>...</th>\n",
       "      <th>dvpsxq</th>\n",
       "      <th>mkvaltq</th>\n",
       "      <th>prccq</th>\n",
       "      <th>prchq</th>\n",
       "      <th>prclq</th>\n",
       "      <th>adjex</th>\n",
       "      <th>ggroup</th>\n",
       "      <th>gind</th>\n",
       "      <th>gsector</th>\n",
       "      <th>gsubind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1447</td>\n",
       "      <td>19990630</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>AXP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.1250</td>\n",
       "      <td>142.6250</td>\n",
       "      <td>114.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>402020</td>\n",
       "      <td>40</td>\n",
       "      <td>40202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1447</td>\n",
       "      <td>19990930</td>\n",
       "      <td>1999</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>AXP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0000</td>\n",
       "      <td>150.6250</td>\n",
       "      <td>121.8750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>402020</td>\n",
       "      <td>40</td>\n",
       "      <td>40202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1447</td>\n",
       "      <td>19991231</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>AXP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.2500</td>\n",
       "      <td>168.8750</td>\n",
       "      <td>130.2500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>402020</td>\n",
       "      <td>40</td>\n",
       "      <td>40202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1447</td>\n",
       "      <td>20000331</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>AXP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.9375</td>\n",
       "      <td>169.5000</td>\n",
       "      <td>119.5000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>402020</td>\n",
       "      <td>40</td>\n",
       "      <td>40202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1447</td>\n",
       "      <td>20000630</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>AXP</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.1250</td>\n",
       "      <td>57.1875</td>\n",
       "      <td>43.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>402020</td>\n",
       "      <td>40</td>\n",
       "      <td>40202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>179534</td>\n",
       "      <td>20200331</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>344931.0935</td>\n",
       "      <td>161.1200</td>\n",
       "      <td>214.1700</td>\n",
       "      <td>133.9300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>179534</td>\n",
       "      <td>20200630</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>412385.7872</td>\n",
       "      <td>193.1700</td>\n",
       "      <td>202.1800</td>\n",
       "      <td>150.6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>179534</td>\n",
       "      <td>20200930</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>426102.7750</td>\n",
       "      <td>199.9700</td>\n",
       "      <td>217.3500</td>\n",
       "      <td>187.1800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>179534</td>\n",
       "      <td>20201231</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320</td>\n",
       "      <td>468920.7015</td>\n",
       "      <td>218.7300</td>\n",
       "      <td>220.3900</td>\n",
       "      <td>179.2300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>179534</td>\n",
       "      <td>20210331</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320</td>\n",
       "      <td>453490.4070</td>\n",
       "      <td>211.7300</td>\n",
       "      <td>228.2298</td>\n",
       "      <td>192.8100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4510</td>\n",
       "      <td>451020</td>\n",
       "      <td>45</td>\n",
       "      <td>45102020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2456 rows × 647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gvkey  datadate  fyearq  fqtr  fyr indfmt consol popsrc datafmt  tic  \\\n",
       "0       1447  19990630    1999     2   12   INDL      C      D     STD  AXP   \n",
       "1       1447  19990930    1999     3   12   INDL      C      D     STD  AXP   \n",
       "2       1447  19991231    1999     4   12   INDL      C      D     STD  AXP   \n",
       "3       1447  20000331    2000     1   12   INDL      C      D     STD  AXP   \n",
       "4       1447  20000630    2000     2   12   INDL      C      D     STD  AXP   \n",
       "...      ...       ...     ...   ...  ...    ...    ...    ...     ...  ...   \n",
       "2451  179534  20200331    2020     2    9   INDL      C      D     STD    V   \n",
       "2452  179534  20200630    2020     3    9   INDL      C      D     STD    V   \n",
       "2453  179534  20200930    2020     4    9   INDL      C      D     STD    V   \n",
       "2454  179534  20201231    2021     1    9   INDL      C      D     STD    V   \n",
       "2455  179534  20210331    2021     2    9   INDL      C      D     STD    V   \n",
       "\n",
       "      ... dvpsxq      mkvaltq     prccq     prchq     prclq  adjex ggroup  \\\n",
       "0     ...  0.225          NaN  130.1250  142.6250  114.5000    3.0   4020   \n",
       "1     ...  0.000          NaN  135.0000  150.6250  121.8750    3.0   4020   \n",
       "2     ...  0.225          NaN  166.2500  168.8750  130.2500    3.0   4020   \n",
       "3     ...  0.225          NaN  148.9375  169.5000  119.5000    3.0   4020   \n",
       "4     ...  0.080          NaN   52.1250   57.1875   43.9375    1.0   4020   \n",
       "...   ...    ...          ...       ...       ...       ...    ...    ...   \n",
       "2451  ...  0.300  344931.0935  161.1200  214.1700  133.9300    1.0   4510   \n",
       "2452  ...  0.300  412385.7872  193.1700  202.1800  150.6000    1.0   4510   \n",
       "2453  ...  0.300  426102.7750  199.9700  217.3500  187.1800    1.0   4510   \n",
       "2454  ...  0.320  468920.7015  218.7300  220.3900  179.2300    1.0   4510   \n",
       "2455  ...  0.320  453490.4070  211.7300  228.2298  192.8100    1.0   4510   \n",
       "\n",
       "        gind gsector   gsubind  \n",
       "0     402020      40  40202010  \n",
       "1     402020      40  40202010  \n",
       "2     402020      40  40202010  \n",
       "3     402020      40  40202010  \n",
       "4     402020      40  40202010  \n",
       "...      ...     ...       ...  \n",
       "2451  451020      45  45102020  \n",
       "2452  451020      45  45102020  \n",
       "2453  451020      45  45102020  \n",
       "2454  451020      45  45102020  \n",
       "2455  451020      45  45102020  \n",
       "\n",
       "[2456 rows x 647 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e533b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List items that are used to calculate financial ratios\n",
    "\n",
    "items = [\n",
    "    'datadate', # Date\n",
    "    'tic', # Ticker\n",
    "    'oiadpq', # Quarterly operating income\n",
    "    'revtq', # Quartely revenue\n",
    "    'niq', # Quartely net income\n",
    "    'atq', # Total asset\n",
    "    'teqq', # Shareholder's equity\n",
    "    'epspiy', # EPS(Basic) incl. Extraordinary items\n",
    "    'ceqq', # Common Equity\n",
    "    'cshoq', # Common Shares Outstanding\n",
    "    'dvpspq', # Dividends per share\n",
    "    'actq', # Current assets\n",
    "    'lctq', # Current liabilities\n",
    "    'cheq', # Cash & Equivalent\n",
    "    'rectq', # Recievalbles\n",
    "    'cogsq', # Cost of  Goods Sold\n",
    "    'invtq', # Inventories\n",
    "    'apq',# Account payable\n",
    "    'dlttq', # Long term debt\n",
    "    'dlcq', # Debt in current liabilites\n",
    "    'ltq' # Liabilities   \n",
    "]\n",
    "\n",
    "# Omit items that will not be used\n",
    "fund_data = fund[items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eeee708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names for the sake of readability\n",
    "fund_data = fund_data.rename(columns={\n",
    "    'datadate':'date', # Date\n",
    "    'oiadpq':'op_inc_q', # Quarterly operating income\n",
    "    'revtq':'rev_q', # Quartely revenue\n",
    "    'niq':'net_inc_q', # Quartely net income\n",
    "    'atq':'tot_assets', # Assets\n",
    "    'teqq':'sh_equity', # Shareholder's equity\n",
    "    'epspiy':'eps_incl_ex', # EPS(Basic) incl. Extraordinary items\n",
    "    'ceqq':'com_eq', # Common Equity\n",
    "    'cshoq':'sh_outstanding', # Common Shares Outstanding\n",
    "    'dvpspq':'div_per_sh', # Dividends per share\n",
    "    'actq':'cur_assets', # Current assets\n",
    "    'lctq':'cur_liabilities', # Current liabilities\n",
    "    'cheq':'cash_eq', # Cash & Equivalent\n",
    "    'rectq':'receivables', # Receivalbles\n",
    "    'cogsq':'cogs_q', # Cost of  Goods Sold\n",
    "    'invtq':'inventories', # Inventories\n",
    "    'apq': 'payables',# Account payable\n",
    "    'dlttq':'long_debt', # Long term debt\n",
    "    'dlcq':'short_debt', # Debt in current liabilites\n",
    "    'ltq':'tot_liabilities' # Liabilities   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db05a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>op_inc_q</th>\n",
       "      <th>rev_q</th>\n",
       "      <th>net_inc_q</th>\n",
       "      <th>tot_assets</th>\n",
       "      <th>sh_equity</th>\n",
       "      <th>eps_incl_ex</th>\n",
       "      <th>com_eq</th>\n",
       "      <th>sh_outstanding</th>\n",
       "      <th>...</th>\n",
       "      <th>cur_assets</th>\n",
       "      <th>cur_liabilities</th>\n",
       "      <th>cash_eq</th>\n",
       "      <th>receivables</th>\n",
       "      <th>cogs_q</th>\n",
       "      <th>inventories</th>\n",
       "      <th>payables</th>\n",
       "      <th>long_debt</th>\n",
       "      <th>short_debt</th>\n",
       "      <th>tot_liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19990630</td>\n",
       "      <td>AXP</td>\n",
       "      <td>896.0</td>\n",
       "      <td>5564.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>132452.0</td>\n",
       "      <td>9762.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>9762.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>46774.0</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>22282.0</td>\n",
       "      <td>7005.0</td>\n",
       "      <td>24785.0</td>\n",
       "      <td>122690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19990930</td>\n",
       "      <td>AXP</td>\n",
       "      <td>906.0</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>132616.0</td>\n",
       "      <td>9744.0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>9744.0</td>\n",
       "      <td>447.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5102.0</td>\n",
       "      <td>48827.0</td>\n",
       "      <td>4678.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>6720.0</td>\n",
       "      <td>24683.0</td>\n",
       "      <td>122872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19991231</td>\n",
       "      <td>AXP</td>\n",
       "      <td>845.0</td>\n",
       "      <td>6009.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>148517.0</td>\n",
       "      <td>10095.0</td>\n",
       "      <td>5.54</td>\n",
       "      <td>10095.0</td>\n",
       "      <td>446.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10391.0</td>\n",
       "      <td>54033.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>25719.0</td>\n",
       "      <td>4685.0</td>\n",
       "      <td>32437.0</td>\n",
       "      <td>138422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000331</td>\n",
       "      <td>AXP</td>\n",
       "      <td>920.0</td>\n",
       "      <td>6021.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>150662.0</td>\n",
       "      <td>10253.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>10253.0</td>\n",
       "      <td>444.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7425.0</td>\n",
       "      <td>53663.0</td>\n",
       "      <td>5101.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>26379.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>29342.0</td>\n",
       "      <td>140409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000630</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>6370.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>148553.0</td>\n",
       "      <td>10509.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>10509.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6841.0</td>\n",
       "      <td>54286.0</td>\n",
       "      <td>5324.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>29536.0</td>\n",
       "      <td>5336.0</td>\n",
       "      <td>26170.0</td>\n",
       "      <td>138044.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  tic  op_inc_q   rev_q  net_inc_q  tot_assets  sh_equity  \\\n",
       "0  19990630  AXP     896.0  5564.0      646.0    132452.0     9762.0   \n",
       "1  19990930  AXP     906.0  5584.0      648.0    132616.0     9744.0   \n",
       "2  19991231  AXP     845.0  6009.0      606.0    148517.0    10095.0   \n",
       "3  20000331  AXP     920.0  6021.0      656.0    150662.0    10253.0   \n",
       "4  20000630  AXP    1046.0  6370.0      740.0    148553.0    10509.0   \n",
       "\n",
       "   eps_incl_ex   com_eq  sh_outstanding  ...  cur_assets  cur_liabilities  \\\n",
       "0         2.73   9762.0           449.0  ...         NaN              NaN   \n",
       "1         4.18   9744.0           447.6  ...         NaN              NaN   \n",
       "2         5.54  10095.0           446.9  ...         NaN              NaN   \n",
       "3         1.48  10253.0           444.7  ...         NaN              NaN   \n",
       "4         1.05  10509.0          1333.0  ...         NaN              NaN   \n",
       "\n",
       "   cash_eq  receivables  cogs_q  inventories  payables  long_debt  short_debt  \\\n",
       "0   6096.0      46774.0  4668.0        448.0   22282.0     7005.0     24785.0   \n",
       "1   5102.0      48827.0  4678.0        284.0   23587.0     6720.0     24683.0   \n",
       "2  10391.0      54033.0  5164.0        277.0   25719.0     4685.0     32437.0   \n",
       "3   7425.0      53663.0  5101.0        315.0   26379.0     5670.0     29342.0   \n",
       "4   6841.0      54286.0  5324.0        261.0   29536.0     5336.0     26170.0   \n",
       "\n",
       "   tot_liabilities  \n",
       "0         122690.0  \n",
       "1         122872.0  \n",
       "2         138422.0  \n",
       "3         140409.0  \n",
       "4         138044.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962c9512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:15: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  OPM.iloc[i] = np.sum(fund_data['op_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  OPM.iloc[i] = np.sum(fund_data['op_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:25: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  NPM.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  NPM.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:77: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  inv_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i])/fund_data['inventories'].iloc[i]\n",
      "/var/folders/gw/j6w6dxq93rj3dzl8s2z_ndf40000gn/T/ipykernel_57403/22741674.py:77: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  inv_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i])/fund_data['inventories'].iloc[i]\n"
     ]
    }
   ],
   "source": [
    "# Calculate financial ratios\n",
    "date = pd.to_datetime(fund_data['date'],format='%Y%m%d')\n",
    "\n",
    "tic = fund_data['tic'].to_frame('tic')\n",
    "\n",
    "# Profitability ratios\n",
    "# Operating Margin\n",
    "OPM = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='OPM')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        OPM[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        OPM.iloc[i] = np.nan\n",
    "    else:\n",
    "        OPM.iloc[i] = np.sum(fund_data['op_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
    "\n",
    "# Net Profit Margin        \n",
    "NPM = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='NPM')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        NPM[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        NPM.iloc[i] = np.nan\n",
    "    else:\n",
    "        NPM.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i])/np.sum(fund_data['rev_q'].iloc[i-3:i])\n",
    "\n",
    "# Return On Assets\n",
    "ROA = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='ROA')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        ROA[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        ROA.iloc[i] = np.nan\n",
    "    else:\n",
    "        ROA.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i])/fund_data['tot_assets'].iloc[i]\n",
    "\n",
    "# Return on Equity\n",
    "ROE = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='ROE')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        ROE[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        ROE.iloc[i] = np.nan\n",
    "    else:\n",
    "        ROE.iloc[i] = np.sum(fund_data['net_inc_q'].iloc[i-3:i])/fund_data['sh_equity'].iloc[i]        \n",
    "\n",
    "# For calculating valuation ratios in the next subpart, calculate per share items in advance\n",
    "# Earnings Per Share       \n",
    "EPS = fund_data['eps_incl_ex'].to_frame('EPS')\n",
    "\n",
    "# Book Per Share\n",
    "BPS = (fund_data['com_eq']/fund_data['sh_outstanding']).to_frame('BPS') # Need to check units\n",
    "\n",
    "#Dividend Per Share\n",
    "DPS = fund_data['div_per_sh'].to_frame('DPS')\n",
    "\n",
    "# Liquidity ratios\n",
    "# Current ratio\n",
    "cur_ratio = (fund_data['cur_assets']/fund_data['cur_liabilities']).to_frame('cur_ratio')\n",
    "\n",
    "# Quick ratio\n",
    "quick_ratio = ((fund_data['cash_eq'] + fund_data['receivables'] )/fund_data['cur_liabilities']).to_frame('quick_ratio')\n",
    "\n",
    "# Cash ratio\n",
    "cash_ratio = (fund_data['cash_eq']/fund_data['cur_liabilities']).to_frame('cash_ratio')\n",
    "\n",
    "\n",
    "# Efficiency ratios\n",
    "# Inventory turnover ratio\n",
    "inv_turnover = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='inv_turnover')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        inv_turnover[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        inv_turnover.iloc[i] = np.nan\n",
    "    else:\n",
    "        inv_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i])/fund_data['inventories'].iloc[i]\n",
    "\n",
    "# Receivables turnover ratio       \n",
    "acc_rec_turnover = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='acc_rec_turnover')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        acc_rec_turnover[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        acc_rec_turnover.iloc[i] = np.nan\n",
    "    else:\n",
    "        acc_rec_turnover.iloc[i] = np.sum(fund_data['rev_q'].iloc[i-3:i])/fund_data['receivables'].iloc[i]\n",
    "\n",
    "# Payable turnover ratio\n",
    "acc_pay_turnover = pd.Series(np.empty(fund_data.shape[0],dtype=object),name='acc_pay_turnover')\n",
    "for i in range(0, fund_data.shape[0]):\n",
    "    if i-3 < 0:\n",
    "        acc_pay_turnover[i] = np.nan\n",
    "    elif fund_data.iloc[i,1] != fund_data.iloc[i-3,1]:\n",
    "        acc_pay_turnover.iloc[i] = np.nan\n",
    "    else:\n",
    "        acc_pay_turnover.iloc[i] = np.sum(fund_data['cogs_q'].iloc[i-3:i])/fund_data['payables'].iloc[i]\n",
    "        \n",
    "## Leverage financial ratios\n",
    "# Debt ratio\n",
    "debt_ratio = (fund_data['tot_liabilities']/fund_data['tot_assets']).to_frame('debt_ratio')\n",
    "\n",
    "# Debt to Equity ratio\n",
    "debt_to_equity = (fund_data['tot_liabilities']/fund_data['sh_equity']).to_frame('debt_to_equity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d7a1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that merges all the ratios\n",
    "ratios = pd.concat([date,tic,OPM,NPM,ROA,ROE,EPS,BPS,DPS,\n",
    "                    cur_ratio,quick_ratio,cash_ratio,inv_turnover,acc_rec_turnover,acc_pay_turnover,\n",
    "                   debt_ratio,debt_to_equity], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "908665dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>EPS</th>\n",
       "      <th>BPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>cur_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73</td>\n",
       "      <td>21.741648</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926298</td>\n",
       "      <td>12.568121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-09-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.18</td>\n",
       "      <td>21.769437</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926525</td>\n",
       "      <td>12.610016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.54</td>\n",
       "      <td>22.588946</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.932028</td>\n",
       "      <td>13.711937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.154281</td>\n",
       "      <td>0.110742</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.185312</td>\n",
       "      <td>1.48</td>\n",
       "      <td>23.055993</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.063492</td>\n",
       "      <td>0.319717</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.931947</td>\n",
       "      <td>13.694431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.151641</td>\n",
       "      <td>0.108436</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.181749</td>\n",
       "      <td>1.05</td>\n",
       "      <td>7.883721</td>\n",
       "      <td>0.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.252874</td>\n",
       "      <td>0.324467</td>\n",
       "      <td>0.505925</td>\n",
       "      <td>0.929258</td>\n",
       "      <td>13.135788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  tic       OPM       NPM       ROA       ROE   EPS        BPS  \\\n",
       "0 1999-06-30  AXP       NaN       NaN       NaN       NaN  2.73  21.741648   \n",
       "1 1999-09-30  AXP       NaN       NaN       NaN       NaN  4.18  21.769437   \n",
       "2 1999-12-31  AXP       NaN       NaN       NaN       NaN  5.54  22.588946   \n",
       "3 2000-03-31  AXP  0.154281  0.110742  0.012611  0.185312  1.48  23.055993   \n",
       "4 2000-06-30  AXP  0.151641  0.108436  0.012857  0.181749  1.05   7.883721   \n",
       "\n",
       "     DPS  cur_ratio  quick_ratio  cash_ratio inv_turnover acc_rec_turnover  \\\n",
       "0  0.225        NaN          NaN         NaN          NaN              NaN   \n",
       "1  0.225        NaN          NaN         NaN          NaN              NaN   \n",
       "2  0.225        NaN          NaN         NaN          NaN              NaN   \n",
       "3  0.225        NaN          NaN         NaN    46.063492         0.319717   \n",
       "4  0.080        NaN          NaN         NaN    57.252874         0.324467   \n",
       "\n",
       "  acc_pay_turnover  debt_ratio  debt_to_equity  \n",
       "0              NaN    0.926298       12.568121  \n",
       "1              NaN    0.926525       12.610016  \n",
       "2              NaN    0.932028       13.711937  \n",
       "3         0.550059    0.931947       13.694431  \n",
       "4         0.505925    0.929258       13.135788  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the ratio data\n",
    "ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6370065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>EPS</th>\n",
       "      <th>BPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>cur_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.667517</td>\n",
       "      <td>0.521213</td>\n",
       "      <td>0.129058</td>\n",
       "      <td>0.271736</td>\n",
       "      <td>2.85</td>\n",
       "      <td>13.647142</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.248714</td>\n",
       "      <td>1.140070</td>\n",
       "      <td>0.955150</td>\n",
       "      <td>inf</td>\n",
       "      <td>6.11635</td>\n",
       "      <td>2.697537</td>\n",
       "      <td>0.525062</td>\n",
       "      <td>1.105537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>0.668385</td>\n",
       "      <td>0.519867</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>0.264075</td>\n",
       "      <td>3.92</td>\n",
       "      <td>14.203947</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.553478</td>\n",
       "      <td>1.443292</td>\n",
       "      <td>1.221925</td>\n",
       "      <td>inf</td>\n",
       "      <td>5.063131</td>\n",
       "      <td>1.889507</td>\n",
       "      <td>0.543886</td>\n",
       "      <td>1.192433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>V</td>\n",
       "      <td>0.654464</td>\n",
       "      <td>0.52129</td>\n",
       "      <td>0.107873</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>4.90</td>\n",
       "      <td>14.653484</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.905238</td>\n",
       "      <td>1.784838</td>\n",
       "      <td>1.579807</td>\n",
       "      <td>inf</td>\n",
       "      <td>5.628571</td>\n",
       "      <td>2.730366</td>\n",
       "      <td>0.552515</td>\n",
       "      <td>1.234714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.638994</td>\n",
       "      <td>0.480876</td>\n",
       "      <td>0.094422</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>1.42</td>\n",
       "      <td>15.908283</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.121065</td>\n",
       "      <td>1.969814</td>\n",
       "      <td>1.700081</td>\n",
       "      <td>inf</td>\n",
       "      <td>4.725314</td>\n",
       "      <td>2.347866</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>1.134505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.640128</td>\n",
       "      <td>0.488704</td>\n",
       "      <td>0.095218</td>\n",
       "      <td>0.202568</td>\n",
       "      <td>2.80</td>\n",
       "      <td>16.088525</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.116356</td>\n",
       "      <td>1.954292</td>\n",
       "      <td>1.700574</td>\n",
       "      <td>inf</td>\n",
       "      <td>4.844961</td>\n",
       "      <td>2.367357</td>\n",
       "      <td>0.529946</td>\n",
       "      <td>1.127414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date tic       OPM       NPM       ROA       ROE   EPS        BPS  \\\n",
       "2451 2020-03-31   V  0.667517  0.521213  0.129058  0.271736  2.85  13.647142   \n",
       "2452 2020-06-30   V  0.668385  0.519867  0.120448  0.264075  3.92  14.203947   \n",
       "2453 2020-09-30   V  0.654464   0.52129  0.107873  0.241066  4.90  14.653484   \n",
       "2454 2020-12-31   V  0.638994  0.480876  0.094422  0.201545  1.42  15.908283   \n",
       "2455 2021-03-31   V  0.640128  0.488704  0.095218  0.202568  2.80  16.088525   \n",
       "\n",
       "       DPS  cur_ratio  quick_ratio  cash_ratio inv_turnover acc_rec_turnover  \\\n",
       "2451  0.30   1.248714     1.140070    0.955150          inf          6.11635   \n",
       "2452  0.30   1.553478     1.443292    1.221925          inf         5.063131   \n",
       "2453  0.30   1.905238     1.784838    1.579807          inf         5.628571   \n",
       "2454  0.32   2.121065     1.969814    1.700081          inf         4.725314   \n",
       "2455  0.32   2.116356     1.954292    1.700574          inf         4.844961   \n",
       "\n",
       "     acc_pay_turnover  debt_ratio  debt_to_equity  \n",
       "2451         2.697537    0.525062        1.105537  \n",
       "2452         1.889507    0.543886        1.192433  \n",
       "2453         2.730366    0.552515        1.234714  \n",
       "2454         2.347866    0.531507        1.134505  \n",
       "2455         2.367357    0.529946        1.127414  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac6832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NAs infinite values with zero\n",
    "final_ratios = ratios.copy()\n",
    "final_ratios = final_ratios.fillna(0)\n",
    "final_ratios = final_ratios.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43a093e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>EPS</th>\n",
       "      <th>BPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>cur_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.73</td>\n",
       "      <td>21.741648</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.926298</td>\n",
       "      <td>12.568121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-09-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.18</td>\n",
       "      <td>21.769437</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.926525</td>\n",
       "      <td>12.610016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.54</td>\n",
       "      <td>22.588946</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.932028</td>\n",
       "      <td>13.711937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.154281</td>\n",
       "      <td>0.110742</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.185312</td>\n",
       "      <td>1.48</td>\n",
       "      <td>23.055993</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.063492</td>\n",
       "      <td>0.319717</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.931947</td>\n",
       "      <td>13.694431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.151641</td>\n",
       "      <td>0.108436</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.181749</td>\n",
       "      <td>1.05</td>\n",
       "      <td>7.883721</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.252874</td>\n",
       "      <td>0.324467</td>\n",
       "      <td>0.505925</td>\n",
       "      <td>0.929258</td>\n",
       "      <td>13.135788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  tic       OPM       NPM       ROA       ROE   EPS        BPS  \\\n",
       "0 1999-06-30  AXP  0.000000  0.000000  0.000000  0.000000  2.73  21.741648   \n",
       "1 1999-09-30  AXP  0.000000  0.000000  0.000000  0.000000  4.18  21.769437   \n",
       "2 1999-12-31  AXP  0.000000  0.000000  0.000000  0.000000  5.54  22.588946   \n",
       "3 2000-03-31  AXP  0.154281  0.110742  0.012611  0.185312  1.48  23.055993   \n",
       "4 2000-06-30  AXP  0.151641  0.108436  0.012857  0.181749  1.05   7.883721   \n",
       "\n",
       "     DPS  cur_ratio  quick_ratio  cash_ratio  inv_turnover  acc_rec_turnover  \\\n",
       "0  0.225        0.0          0.0         0.0      0.000000          0.000000   \n",
       "1  0.225        0.0          0.0         0.0      0.000000          0.000000   \n",
       "2  0.225        0.0          0.0         0.0      0.000000          0.000000   \n",
       "3  0.225        0.0          0.0         0.0     46.063492          0.319717   \n",
       "4  0.080        0.0          0.0         0.0     57.252874          0.324467   \n",
       "\n",
       "   acc_pay_turnover  debt_ratio  debt_to_equity  \n",
       "0          0.000000    0.926298       12.568121  \n",
       "1          0.000000    0.926525       12.610016  \n",
       "2          0.000000    0.932028       13.711937  \n",
       "3          0.550059    0.931947       13.694431  \n",
       "4          0.505925    0.929258       13.135788  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ef1fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>EPS</th>\n",
       "      <th>BPS</th>\n",
       "      <th>DPS</th>\n",
       "      <th>cur_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.667517</td>\n",
       "      <td>0.521213</td>\n",
       "      <td>0.129058</td>\n",
       "      <td>0.271736</td>\n",
       "      <td>2.85</td>\n",
       "      <td>13.647142</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.248714</td>\n",
       "      <td>1.140070</td>\n",
       "      <td>0.955150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.116350</td>\n",
       "      <td>2.697537</td>\n",
       "      <td>0.525062</td>\n",
       "      <td>1.105537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>0.668385</td>\n",
       "      <td>0.519867</td>\n",
       "      <td>0.120448</td>\n",
       "      <td>0.264075</td>\n",
       "      <td>3.92</td>\n",
       "      <td>14.203947</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.553478</td>\n",
       "      <td>1.443292</td>\n",
       "      <td>1.221925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.063131</td>\n",
       "      <td>1.889507</td>\n",
       "      <td>0.543886</td>\n",
       "      <td>1.192433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>V</td>\n",
       "      <td>0.654464</td>\n",
       "      <td>0.521290</td>\n",
       "      <td>0.107873</td>\n",
       "      <td>0.241066</td>\n",
       "      <td>4.90</td>\n",
       "      <td>14.653484</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.905238</td>\n",
       "      <td>1.784838</td>\n",
       "      <td>1.579807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.628571</td>\n",
       "      <td>2.730366</td>\n",
       "      <td>0.552515</td>\n",
       "      <td>1.234714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.638994</td>\n",
       "      <td>0.480876</td>\n",
       "      <td>0.094422</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>1.42</td>\n",
       "      <td>15.908283</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.121065</td>\n",
       "      <td>1.969814</td>\n",
       "      <td>1.700081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.725314</td>\n",
       "      <td>2.347866</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>1.134505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>V</td>\n",
       "      <td>0.640128</td>\n",
       "      <td>0.488704</td>\n",
       "      <td>0.095218</td>\n",
       "      <td>0.202568</td>\n",
       "      <td>2.80</td>\n",
       "      <td>16.088525</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.116356</td>\n",
       "      <td>1.954292</td>\n",
       "      <td>1.700574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.844961</td>\n",
       "      <td>2.367357</td>\n",
       "      <td>0.529946</td>\n",
       "      <td>1.127414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date tic       OPM       NPM       ROA       ROE   EPS        BPS  \\\n",
       "2451 2020-03-31   V  0.667517  0.521213  0.129058  0.271736  2.85  13.647142   \n",
       "2452 2020-06-30   V  0.668385  0.519867  0.120448  0.264075  3.92  14.203947   \n",
       "2453 2020-09-30   V  0.654464  0.521290  0.107873  0.241066  4.90  14.653484   \n",
       "2454 2020-12-31   V  0.638994  0.480876  0.094422  0.201545  1.42  15.908283   \n",
       "2455 2021-03-31   V  0.640128  0.488704  0.095218  0.202568  2.80  16.088525   \n",
       "\n",
       "       DPS  cur_ratio  quick_ratio  cash_ratio  inv_turnover  \\\n",
       "2451  0.30   1.248714     1.140070    0.955150           0.0   \n",
       "2452  0.30   1.553478     1.443292    1.221925           0.0   \n",
       "2453  0.30   1.905238     1.784838    1.579807           0.0   \n",
       "2454  0.32   2.121065     1.969814    1.700081           0.0   \n",
       "2455  0.32   2.116356     1.954292    1.700574           0.0   \n",
       "\n",
       "      acc_rec_turnover  acc_pay_turnover  debt_ratio  debt_to_equity  \n",
       "2451          6.116350          2.697537    0.525062        1.105537  \n",
       "2452          5.063131          1.889507    0.543886        1.192433  \n",
       "2453          5.628571          2.730366    0.552515        1.234714  \n",
       "2454          4.725314          2.347866    0.531507        1.134505  \n",
       "2455          4.844961          2.367357    0.529946        1.127414  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ratios.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7545fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(df['date'].min(),df['date'].max()))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# Merge stock price data and ratios into one dataframe\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full.merge(final_ratios,how='left',on=['date','tic'])\n",
    "processed_full = processed_full.sort_values(['tic','date'])\n",
    "\n",
    "# Backfill the ratio data to make them daily\n",
    "processed_full = processed_full.bfill(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77068c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P/E, P/B and dividend yield using daily closing price\n",
    "processed_full['PE'] = processed_full['close']/processed_full['EPS']\n",
    "processed_full['PB'] = processed_full['close']/processed_full['BPS']\n",
    "processed_full['Div_yield'] = processed_full['DPS']/processed_full['close']\n",
    "\n",
    "# Drop per share items used for the above calculation\n",
    "processed_full = processed_full.drop(columns=['day','EPS','BPS','DPS'])\n",
    "# Replace NAs infinite values with zero\n",
    "processed_full = processed_full.copy()\n",
    "processed_full = processed_full.fillna(0)\n",
    "processed_full = processed_full.replace(np.inf,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f1c279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>...</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "      <th>PE</th>\n",
       "      <th>PB</th>\n",
       "      <th>Div_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.751010</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>0.217886</td>\n",
       "      <td>0.163846</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039779</td>\n",
       "      <td>1.818995</td>\n",
       "      <td>54.403846</td>\n",
       "      <td>8.972003</td>\n",
       "      <td>4.269115</td>\n",
       "      <td>0.437727</td>\n",
       "      <td>0.778495</td>\n",
       "      <td>0.632416</td>\n",
       "      <td>0.100928</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>43.073929</td>\n",
       "      <td>6547900.0</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351354</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.869784</td>\n",
       "      <td>6.679531</td>\n",
       "      <td>138.948158</td>\n",
       "      <td>3.989086</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.256275</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351354</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.869784</td>\n",
       "      <td>6.679531</td>\n",
       "      <td>49.213791</td>\n",
       "      <td>1.412887</td>\n",
       "      <td>0.011798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941113</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>0.047307</td>\n",
       "      <td>0.032525</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368463</td>\n",
       "      <td>0.148507</td>\n",
       "      <td>2.329670</td>\n",
       "      <td>6.815203</td>\n",
       "      <td>2.076967</td>\n",
       "      <td>1.009198</td>\n",
       "      <td>-109.722986</td>\n",
       "      <td>39.012773</td>\n",
       "      <td>-35.751066</td>\n",
       "      <td>0.012374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>31.254059</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>0.124545</td>\n",
       "      <td>0.066662</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890488</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>3.540791</td>\n",
       "      <td>2.460351</td>\n",
       "      <td>8.472455</td>\n",
       "      <td>0.893715</td>\n",
       "      <td>9.089489</td>\n",
       "      <td>-164.495047</td>\n",
       "      <td>3.016663</td>\n",
       "      <td>0.013438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CRM</td>\n",
       "      <td>8.025000</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>7.912500</td>\n",
       "      <td>8.505000</td>\n",
       "      <td>4069200.0</td>\n",
       "      <td>0.234698</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>0.097593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498162</td>\n",
       "      <td>2.170759</td>\n",
       "      <td>9.054201</td>\n",
       "      <td>6.844634</td>\n",
       "      <td>16.036800</td>\n",
       "      <td>0.400215</td>\n",
       "      <td>0.667591</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>1.351255</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>11.770000</td>\n",
       "      <td>40980600.0</td>\n",
       "      <td>0.234698</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>0.097593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498162</td>\n",
       "      <td>2.170759</td>\n",
       "      <td>9.054201</td>\n",
       "      <td>6.844634</td>\n",
       "      <td>16.036800</td>\n",
       "      <td>0.400215</td>\n",
       "      <td>0.667591</td>\n",
       "      <td>18.682539</td>\n",
       "      <td>1.869991</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CVX</td>\n",
       "      <td>74.230003</td>\n",
       "      <td>77.300003</td>\n",
       "      <td>73.580002</td>\n",
       "      <td>42.841904</td>\n",
       "      <td>13695900.0</td>\n",
       "      <td>0.141417</td>\n",
       "      <td>0.097223</td>\n",
       "      <td>0.117691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952878</td>\n",
       "      <td>0.373760</td>\n",
       "      <td>23.920348</td>\n",
       "      <td>13.387209</td>\n",
       "      <td>11.276861</td>\n",
       "      <td>0.449174</td>\n",
       "      <td>0.815455</td>\n",
       "      <td>46.567287</td>\n",
       "      <td>0.983633</td>\n",
       "      <td>0.015172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.760000</td>\n",
       "      <td>24.030001</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>20.597498</td>\n",
       "      <td>9796600.0</td>\n",
       "      <td>0.167221</td>\n",
       "      <td>0.102157</td>\n",
       "      <td>0.045834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815629</td>\n",
       "      <td>0.330748</td>\n",
       "      <td>11.310223</td>\n",
       "      <td>5.725855</td>\n",
       "      <td>4.287167</td>\n",
       "      <td>0.455848</td>\n",
       "      <td>0.837721</td>\n",
       "      <td>26.072782</td>\n",
       "      <td>1.126511</td>\n",
       "      <td>0.016992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>DOW</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>39.238800</td>\n",
       "      <td>2350800.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>170.603478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   tic       open       high        low      close       volume  \\\n",
       "0 2009-01-02  AAPL   3.067143   3.251429   3.041429   2.751010  746015200.0   \n",
       "1 2009-01-02  AMGN  58.590000  59.080002  57.750000  43.073929    6547900.0   \n",
       "2 2009-01-02   AXP  18.570000  19.520000  18.400000  15.256275   10955700.0   \n",
       "3 2009-01-02    BA  42.799999  45.560001  42.779999  33.941113    7010200.0   \n",
       "4 2009-01-02   CAT  44.910000  46.980000  44.709999  31.254059    7117200.0   \n",
       "5 2009-01-02   CRM   8.025000   8.550000   7.912500   8.505000    4069200.0   \n",
       "6 2009-01-02  CSCO  16.410000  17.000000  16.250000  11.770000   40980600.0   \n",
       "7 2009-01-02   CVX  74.230003  77.300003  73.580002  42.841904   13695900.0   \n",
       "8 2009-01-02   DIS  22.760000  24.030001  22.500000  20.597498    9796600.0   \n",
       "9 2009-01-02   DOW  52.750000  53.500000  49.500000  39.238800    2350800.0   \n",
       "\n",
       "        OPM       NPM       ROA  ...  quick_ratio  cash_ratio  inv_turnover  \\\n",
       "0  0.217886  0.163846  0.103222  ...     2.039779    1.818995     54.403846   \n",
       "1  0.093973  0.072040  0.014094  ...     0.000000    0.000000      0.000000   \n",
       "2  0.093973  0.072040  0.014094  ...     0.000000    0.000000      0.000000   \n",
       "3  0.047307  0.032525  0.026400  ...     0.368463    0.148507      2.329670   \n",
       "4  0.124545  0.066662  0.040891  ...     0.890488    0.163158      3.540791   \n",
       "5  0.234698  0.196418  0.097593  ...     2.498162    2.170759      9.054201   \n",
       "6  0.234698  0.196418  0.097593  ...     2.498162    2.170759      9.054201   \n",
       "7  0.141417  0.097223  0.117691  ...     0.952878    0.373760     23.920348   \n",
       "8  0.167221  0.102157  0.045834  ...     0.815629    0.330748     11.310223   \n",
       "9  0.000000  0.000000  0.000000  ...     0.000000    0.000000      0.000000   \n",
       "\n",
       "   acc_rec_turnover  acc_pay_turnover  debt_ratio  debt_to_equity          PE  \\\n",
       "0          8.972003          4.269115    0.437727        0.778495    0.632416   \n",
       "1          0.351354          0.653355    0.869784        6.679531  138.948158   \n",
       "2          0.351354          0.653355    0.869784        6.679531   49.213791   \n",
       "3          6.815203          2.076967    1.009198     -109.722986   39.012773   \n",
       "4          2.460351          8.472455    0.893715        9.089489 -164.495047   \n",
       "5          6.844634         16.036800    0.400215        0.667591   13.500000   \n",
       "6          6.844634         16.036800    0.400215        0.667591   18.682539   \n",
       "7         13.387209         11.276861    0.449174        0.815455   46.567287   \n",
       "8          5.725855          4.287167    0.455848        0.837721   26.072782   \n",
       "9          0.000000          0.000000    0.000000        0.000000  170.603478   \n",
       "\n",
       "          PB  Div_yield  \n",
       "0   0.100928   0.000000  \n",
       "1   3.989086   0.004179  \n",
       "2   1.412887   0.011798  \n",
       "3 -35.751066   0.012374  \n",
       "4   3.016663   0.013438  \n",
       "5   1.351255   0.000000  \n",
       "6   1.869991   0.000000  \n",
       "7   0.983633   0.015172  \n",
       "8   1.126511   0.016992  \n",
       "9   0.000000   0.000000  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the final data\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa1692f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109530\n",
      "21930\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2019-01-01')\n",
    "trade = data_split(processed_full, '2019-01-01','2021-01-01')\n",
    "# Check the length of the two datasets\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "551d9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>...</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "      <th>PE</th>\n",
       "      <th>PB</th>\n",
       "      <th>Div_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.751010</td>\n",
       "      <td>746015200.0</td>\n",
       "      <td>0.217886</td>\n",
       "      <td>0.163846</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039779</td>\n",
       "      <td>1.818995</td>\n",
       "      <td>54.403846</td>\n",
       "      <td>8.972003</td>\n",
       "      <td>4.269115</td>\n",
       "      <td>0.437727</td>\n",
       "      <td>0.778495</td>\n",
       "      <td>0.632416</td>\n",
       "      <td>0.100928</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>43.073929</td>\n",
       "      <td>6547900.0</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351354</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.869784</td>\n",
       "      <td>6.679531</td>\n",
       "      <td>138.948158</td>\n",
       "      <td>3.989086</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>15.256275</td>\n",
       "      <td>10955700.0</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351354</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.869784</td>\n",
       "      <td>6.679531</td>\n",
       "      <td>49.213791</td>\n",
       "      <td>1.412887</td>\n",
       "      <td>0.011798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>33.941113</td>\n",
       "      <td>7010200.0</td>\n",
       "      <td>0.047307</td>\n",
       "      <td>0.032525</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368463</td>\n",
       "      <td>0.148507</td>\n",
       "      <td>2.329670</td>\n",
       "      <td>6.815203</td>\n",
       "      <td>2.076967</td>\n",
       "      <td>1.009198</td>\n",
       "      <td>-109.722986</td>\n",
       "      <td>39.012773</td>\n",
       "      <td>-35.751066</td>\n",
       "      <td>0.012374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>31.254059</td>\n",
       "      <td>7117200.0</td>\n",
       "      <td>0.124545</td>\n",
       "      <td>0.066662</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890488</td>\n",
       "      <td>0.163158</td>\n",
       "      <td>3.540791</td>\n",
       "      <td>2.460351</td>\n",
       "      <td>8.472455</td>\n",
       "      <td>0.893715</td>\n",
       "      <td>9.089489</td>\n",
       "      <td>-164.495047</td>\n",
       "      <td>3.016663</td>\n",
       "      <td>0.013438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   tic       open       high        low      close       volume  \\\n",
       "0 2009-01-02  AAPL   3.067143   3.251429   3.041429   2.751010  746015200.0   \n",
       "0 2009-01-02  AMGN  58.590000  59.080002  57.750000  43.073929    6547900.0   \n",
       "0 2009-01-02   AXP  18.570000  19.520000  18.400000  15.256275   10955700.0   \n",
       "0 2009-01-02    BA  42.799999  45.560001  42.779999  33.941113    7010200.0   \n",
       "0 2009-01-02   CAT  44.910000  46.980000  44.709999  31.254059    7117200.0   \n",
       "\n",
       "        OPM       NPM       ROA  ...  quick_ratio  cash_ratio  inv_turnover  \\\n",
       "0  0.217886  0.163846  0.103222  ...     2.039779    1.818995     54.403846   \n",
       "0  0.093973  0.072040  0.014094  ...     0.000000    0.000000      0.000000   \n",
       "0  0.093973  0.072040  0.014094  ...     0.000000    0.000000      0.000000   \n",
       "0  0.047307  0.032525  0.026400  ...     0.368463    0.148507      2.329670   \n",
       "0  0.124545  0.066662  0.040891  ...     0.890488    0.163158      3.540791   \n",
       "\n",
       "   acc_rec_turnover  acc_pay_turnover  debt_ratio  debt_to_equity          PE  \\\n",
       "0          8.972003          4.269115    0.437727        0.778495    0.632416   \n",
       "0          0.351354          0.653355    0.869784        6.679531  138.948158   \n",
       "0          0.351354          0.653355    0.869784        6.679531   49.213791   \n",
       "0          6.815203          2.076967    1.009198     -109.722986   39.012773   \n",
       "0          2.460351          8.472455    0.893715        9.089489 -164.495047   \n",
       "\n",
       "          PB  Div_yield  \n",
       "0   0.100928   0.000000  \n",
       "0   3.989086   0.004179  \n",
       "0   1.412887   0.011798  \n",
       "0 -35.751066   0.012374  \n",
       "0   3.016663   0.013438  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68ddec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>OPM</th>\n",
       "      <th>NPM</th>\n",
       "      <th>ROA</th>\n",
       "      <th>...</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>inv_turnover</th>\n",
       "      <th>acc_rec_turnover</th>\n",
       "      <th>acc_pay_turnover</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity</th>\n",
       "      <th>PE</th>\n",
       "      <th>PB</th>\n",
       "      <th>Div_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>37.943256</td>\n",
       "      <td>148158800.0</td>\n",
       "      <td>0.258891</td>\n",
       "      <td>0.227773</td>\n",
       "      <td>0.133360</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134347</td>\n",
       "      <td>0.854114</td>\n",
       "      <td>23.571867</td>\n",
       "      <td>7.620024</td>\n",
       "      <td>3.781658</td>\n",
       "      <td>0.690466</td>\n",
       "      <td>2.230663</td>\n",
       "      <td>5.663173</td>\n",
       "      <td>1.651383</td>\n",
       "      <td>0.019239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>192.520004</td>\n",
       "      <td>193.199997</td>\n",
       "      <td>188.949997</td>\n",
       "      <td>165.993103</td>\n",
       "      <td>3009100.0</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.072040</td>\n",
       "      <td>0.014094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351354</td>\n",
       "      <td>0.653355</td>\n",
       "      <td>0.869784</td>\n",
       "      <td>6.679531</td>\n",
       "      <td>535.461623</td>\n",
       "      <td>15.372657</td>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>93.910004</td>\n",
       "      <td>96.269997</td>\n",
       "      <td>93.769997</td>\n",
       "      <td>89.451683</td>\n",
       "      <td>4175400.0</td>\n",
       "      <td>0.203479</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.026811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231669</td>\n",
       "      <td>0.279424</td>\n",
       "      <td>0.887329</td>\n",
       "      <td>7.875371</td>\n",
       "      <td>49.420819</td>\n",
       "      <td>3.369838</td>\n",
       "      <td>0.004360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>316.190002</td>\n",
       "      <td>323.950012</td>\n",
       "      <td>313.709991</td>\n",
       "      <td>314.645142</td>\n",
       "      <td>3292200.0</td>\n",
       "      <td>0.116496</td>\n",
       "      <td>0.102682</td>\n",
       "      <td>0.066409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262465</td>\n",
       "      <td>0.092436</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>5.468453</td>\n",
       "      <td>4.151637</td>\n",
       "      <td>0.998070</td>\n",
       "      <td>517.142241</td>\n",
       "      <td>83.019826</td>\n",
       "      <td>1418.196271</td>\n",
       "      <td>0.006531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>124.029999</td>\n",
       "      <td>127.879997</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>112.465012</td>\n",
       "      <td>4783200.0</td>\n",
       "      <td>0.186871</td>\n",
       "      <td>0.107064</td>\n",
       "      <td>0.056932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919490</td>\n",
       "      <td>0.266175</td>\n",
       "      <td>2.135008</td>\n",
       "      <td>2.339630</td>\n",
       "      <td>3.660183</td>\n",
       "      <td>0.803394</td>\n",
       "      <td>4.086316</td>\n",
       "      <td>34.183894</td>\n",
       "      <td>4.165089</td>\n",
       "      <td>0.007647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   tic        open        high         low       close  \\\n",
       "0 2019-01-01  AAPL   38.722500   39.712502   38.557499   37.943256   \n",
       "0 2019-01-01  AMGN  192.520004  193.199997  188.949997  165.993103   \n",
       "0 2019-01-01   AXP   93.910004   96.269997   93.769997   89.451683   \n",
       "0 2019-01-01    BA  316.190002  323.950012  313.709991  314.645142   \n",
       "0 2019-01-01   CAT  124.029999  127.879997  123.000000  112.465012   \n",
       "\n",
       "        volume       OPM       NPM       ROA  ...  quick_ratio  cash_ratio  \\\n",
       "0  148158800.0  0.258891  0.227773  0.133360  ...     1.134347    0.854114   \n",
       "0    3009100.0  0.093973  0.072040  0.014094  ...     0.000000    0.000000   \n",
       "0    4175400.0  0.203479  0.160494  0.026811  ...     0.000000    0.000000   \n",
       "0    3292200.0  0.116496  0.102682  0.066409  ...     0.262465    0.092436   \n",
       "0    4783200.0  0.186871  0.107064  0.056932  ...     0.919490    0.266175   \n",
       "\n",
       "   inv_turnover  acc_rec_turnover  acc_pay_turnover  debt_ratio  \\\n",
       "0     23.571867          7.620024          3.781658    0.690466   \n",
       "0      0.000000          0.351354          0.653355    0.869784   \n",
       "0      0.000000          0.231669          0.279424    0.887329   \n",
       "0      0.933164          5.468453          4.151637    0.998070   \n",
       "0      2.135008          2.339630          3.660183    0.803394   \n",
       "\n",
       "   debt_to_equity          PE           PB  Div_yield  \n",
       "0        2.230663    5.663173     1.651383   0.019239  \n",
       "0        6.679531  535.461623    15.372657   0.001084  \n",
       "0        7.875371   49.420819     3.369838   0.004360  \n",
       "0      517.142241   83.019826  1418.196271   0.006531  \n",
       "0        4.086316   34.183894     4.165089   0.007647  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "face9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# from stable_baselines3.common import logger\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        stock_dim,\n",
    "        hmax,\n",
    "        initial_amount,\n",
    "        buy_cost_pct,\n",
    "        sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        tech_indicator_list,\n",
    "        turbulence_threshold=None,\n",
    "        risk_indicator_col=\"turbulence\",\n",
    "        make_plots=False,\n",
    "        print_verbosity=10,\n",
    "        day=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        iteration=\"\",\n",
    "    ):\n",
    "        self.day = day\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.state_space,)\n",
    "        )\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        self.risk_indicator_col = risk_indicator_col\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        # initalize state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        # self.reset()\n",
    "        self._seed()\n",
    "\n",
    "    def _sell_stock(self, index, action):\n",
    "        def _do_sell_normal():\n",
    "            if self.state[index + 1] > 0:\n",
    "                # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                # perform sell action based on the sign of the action\n",
    "                if self.state[index + self.stock_dim + 1] > 0:\n",
    "                    # Sell only if current asset is > 0\n",
    "                    sell_num_shares = min(\n",
    "                        abs(action), self.state[index + self.stock_dim + 1]\n",
    "                    )\n",
    "                    sell_amount = (\n",
    "                        self.state[index + 1]\n",
    "                        * sell_num_shares\n",
    "                        * (1 - self.sell_cost_pct)\n",
    "                    )\n",
    "                    # update balance\n",
    "                    self.state[0] += sell_amount\n",
    "\n",
    "                    self.state[index + self.stock_dim + 1] -= sell_num_shares\n",
    "                    self.cost += (\n",
    "                        self.state[index + 1] * sell_num_shares * self.sell_cost_pct\n",
    "                    )\n",
    "                    self.trades += 1\n",
    "                else:\n",
    "                    sell_num_shares = 0\n",
    "            else:\n",
    "                sell_num_shares = 0\n",
    "\n",
    "            return sell_num_shares\n",
    "\n",
    "        # perform sell action based on the sign of the action\n",
    "        if self.turbulence_threshold is not None:\n",
    "            if self.turbulence >= self.turbulence_threshold:\n",
    "                if self.state[index + 1] > 0:\n",
    "                    # Sell only if the price is > 0 (no missing data in this particular date)\n",
    "                    # if turbulence goes over threshold, just clear out all positions\n",
    "                    if self.state[index + self.stock_dim + 1] > 0:\n",
    "                        # Sell only if current asset is > 0\n",
    "                        sell_num_shares = self.state[index + self.stock_dim + 1]\n",
    "                        sell_amount = (\n",
    "                            self.state[index + 1]\n",
    "                            * sell_num_shares\n",
    "                            * (1 - self.sell_cost_pct)\n",
    "                        )\n",
    "                        # update balance\n",
    "                        self.state[0] += sell_amount\n",
    "                        self.state[index + self.stock_dim + 1] = 0\n",
    "                        self.cost += (\n",
    "                            self.state[index + 1] * sell_num_shares * self.sell_cost_pct\n",
    "                        )\n",
    "                        self.trades += 1\n",
    "                    else:\n",
    "                        sell_num_shares = 0\n",
    "                else:\n",
    "                    sell_num_shares = 0\n",
    "            else:\n",
    "                sell_num_shares = _do_sell_normal()\n",
    "        else:\n",
    "            sell_num_shares = _do_sell_normal()\n",
    "\n",
    "        return sell_num_shares\n",
    "\n",
    "    def _buy_stock(self, index, action):\n",
    "        def _do_buy():\n",
    "            if self.state[index + 1] > 0:\n",
    "                # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                available_amount = self.state[0] // self.state[index + 1]\n",
    "                # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "                # update balance\n",
    "                buy_num_shares = min(available_amount, action)\n",
    "                buy_amount = (\n",
    "                    self.state[index + 1] * buy_num_shares * (1 + self.buy_cost_pct)\n",
    "                )\n",
    "                self.state[0] -= buy_amount\n",
    "\n",
    "                self.state[index + self.stock_dim + 1] += buy_num_shares\n",
    "\n",
    "                self.cost += self.state[index + 1] * buy_num_shares * self.buy_cost_pct\n",
    "                self.trades += 1\n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "        # perform buy action based on the sign of the action\n",
    "        if self.turbulence_threshold is None:\n",
    "            buy_num_shares = _do_buy()\n",
    "        else:\n",
    "            if self.turbulence < self.turbulence_threshold:\n",
    "                buy_num_shares = _do_buy()\n",
    "            else:\n",
    "                buy_num_shares = 0\n",
    "                pass\n",
    "\n",
    "        return buy_num_shares\n",
    "\n",
    "    def _make_plot(self):\n",
    "        plt.plot(self.asset_memory, \"r\")\n",
    "        plt.savefig(\"results/account_value_trade_{}.png\".format(self.episode))\n",
    "        plt.close()\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "        if self.terminal:\n",
    "            # print(f\"Episode: {self.episode}\")\n",
    "            if self.make_plots:\n",
    "                self._make_plot()\n",
    "            end_total_asset = self.state[0] + sum(\n",
    "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "            )\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            tot_reward = (\n",
    "                self.state[0]\n",
    "                + sum(\n",
    "                    np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "                    * np.array(\n",
    "                        self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
    "                    )\n",
    "                )\n",
    "                - self.initial_amount\n",
    "            )\n",
    "            df_total_value.columns = [\"account_value\"]\n",
    "            df_total_value[\"date\"] = self.date_memory\n",
    "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(\n",
    "                1\n",
    "            )\n",
    "            if df_total_value[\"daily_return\"].std() != 0:\n",
    "                sharpe = (\n",
    "                    (252 ** 0.5)\n",
    "                    * df_total_value[\"daily_return\"].mean()\n",
    "                    / df_total_value[\"daily_return\"].std()\n",
    "                )\n",
    "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            df_rewards.columns = [\"account_rewards\"]\n",
    "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
    "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                if df_total_value[\"daily_return\"].std() != 0:\n",
    "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "\n",
    "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
    "                df_actions = self.save_action_memory()\n",
    "                df_actions.to_csv(\n",
    "                    \"results/actions_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    )\n",
    "                )\n",
    "                df_total_value.to_csv(\n",
    "                    \"results/account_value_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                df_rewards.to_csv(\n",
    "                    \"results/account_rewards_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.plot(self.asset_memory, \"r\")\n",
    "                plt.savefig(\n",
    "                    \"results/account_value_{}_{}_{}.png\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.close()\n",
    "\n",
    "            # Add outputs to logger interface\n",
    "            # logger.record(\"environment/portfolio_value\", end_total_asset)\n",
    "            # logger.record(\"environment/total_reward\", tot_reward)\n",
    "            # logger.record(\"environment/total_reward_pct\", (tot_reward / (end_total_asset - tot_reward)) * 100)\n",
    "            # logger.record(\"environment/total_cost\", self.cost)\n",
    "            # logger.record(\"environment/total_trades\", self.trades)\n",
    "\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "\n",
    "            actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
    "            actions = actions.astype(\n",
    "                int\n",
    "            )  # convert into integer because we can't by fraction of shares\n",
    "            if self.turbulence_threshold is not None:\n",
    "                if self.turbulence >= self.turbulence_threshold:\n",
    "                    actions = np.array([-self.hmax] * self.stock_dim)\n",
    "            begin_total_asset = self.state[0] + sum(\n",
    "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "            )\n",
    "            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "\n",
    "            argsort_actions = np.argsort(actions)\n",
    "\n",
    "            sell_index = argsort_actions[: np.where(actions < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][: np.where(actions > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print(f\"Num shares before: {self.state[index+self.stock_dim+1]}\")\n",
    "                # print(f'take sell action before : {actions[index]}')\n",
    "                actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
    "                # print(f'take sell action after : {actions[index]}')\n",
    "                # print(f\"Num shares after: {self.state[index+self.stock_dim+1]}\")\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                actions[index] = self._buy_stock(index, actions[index])\n",
    "\n",
    "            self.actions_memory.append(actions)\n",
    "\n",
    "            # state: s -> s+1\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            if self.turbulence_threshold is not None:\n",
    "                if len(self.df.tic.unique()) == 1:\n",
    "                    self.turbulence = self.data[self.risk_indicator_col]\n",
    "                elif len(self.df.tic.unique()) > 1:\n",
    "                    self.turbulence = self.data[self.risk_indicator_col].values[0]\n",
    "            self.state = self._update_state()\n",
    "\n",
    "            end_total_asset = self.state[0] + sum(\n",
    "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "                * np.array(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "            )\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            self.date_memory.append(self._get_date())\n",
    "            self.reward = end_total_asset - begin_total_asset\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            self.reward = self.reward * self.reward_scaling\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # initiate state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        if self.initial:\n",
    "            self.asset_memory = [self.initial_amount]\n",
    "        else:\n",
    "            previous_total_asset = self.previous_state[0] + sum(\n",
    "                np.array(self.state[1 : (self.stock_dim + 1)])\n",
    "                * np.array(\n",
    "                    self.previous_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)]\n",
    "                )\n",
    "            )\n",
    "            self.asset_memory = [previous_total_asset]\n",
    "\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        # self.iteration=self.iteration\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "\n",
    "        self.episode += 1\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        if self.initial:\n",
    "            # For Initial State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[tech].values.tolist()\n",
    "                            for tech in self.tech_indicator_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.data.close]\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
    "                )\n",
    "        else:\n",
    "            # Using Previous State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + self.data.close.values.tolist()\n",
    "                    + self.previous_state[\n",
    "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
    "                    ]\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[tech].values.tolist()\n",
    "                            for tech in self.tech_indicator_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + [self.data.close]\n",
    "                    + self.previous_state[\n",
    "                        (self.stock_dim + 1) : (self.stock_dim * 2 + 1)\n",
    "                    ]\n",
    "                    + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
    "                )\n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # for multiple stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + self.data.close.values.tolist()\n",
    "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "                + sum(\n",
    "                    [\n",
    "                        self.data[tech].values.tolist()\n",
    "                        for tech in self.tech_indicator_list\n",
    "                    ],\n",
    "                    [],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # for single stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + [self.data.close]\n",
    "                + list(self.state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)])\n",
    "                + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
    "            )\n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            date = self.data.date.unique()[0]\n",
    "        else:\n",
    "            date = self.data.date\n",
    "        return date\n",
    "\n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        asset_list = self.asset_memory\n",
    "        # print(len(date_list))\n",
    "        # print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"account_value\": asset_list}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # date and close price length must match actions length\n",
    "            date_list = self.date_memory[:-1]\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            df_actions.columns = self.data.tic.values\n",
    "            df_actions.index = df_date.date\n",
    "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        else:\n",
    "            date_list = self.date_memory[:-1]\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46c1704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 511\n"
     ]
    }
   ],
   "source": [
    "ratio_list = ['OPM', 'NPM','ROA', 'ROE', 'cur_ratio', 'quick_ratio', 'cash_ratio', 'inv_turnover','acc_rec_turnover', 'acc_pay_turnover', 'debt_ratio', 'debt_to_equity',\n",
    "       'PE', 'PB', 'Div_yield']\n",
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(ratio_list)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22a694b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the environment\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": ratio_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "#Establish the training environment using StockTradingEnv() class\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9d166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuding/opt/anaconda3/envs/finRL/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8e6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRL models from Stable Baselines 3\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.noise import (\n",
    "    NormalActionNoise,\n",
    "    OrnsteinUhlenbeckActionNoise,\n",
    ")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from finrl import config\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "\n",
    "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "\n",
    "MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
    "\n",
    "NOISE = {\n",
    "    \"normal\": NormalActionNoise,\n",
    "    \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
    "}\n",
    "\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        try:\n",
    "            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n",
    "        except BaseException:\n",
    "            self.logger.record(key=\"train/reward\", value=self.locals[\"reward\"][0])\n",
    "        return True\n",
    "\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"Provides implementations for DRL algorithms\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        env: gym environment class\n",
    "            user-defined class\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "        get_model()\n",
    "            setup DRL algorithms\n",
    "        train_model()\n",
    "            train DRL algorithms in a train dataset\n",
    "            and output the trained model\n",
    "        DRL_prediction()\n",
    "            make a prediction in a test dataset and get results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def get_model(\n",
    "            self,\n",
    "            model_name,\n",
    "            policy=\"MlpPolicy\",\n",
    "            policy_kwargs=None,\n",
    "            model_kwargs=None,\n",
    "            verbose=1,\n",
    "            seed=None,\n",
    "            tensorboard_log=None,\n",
    "    ):\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = MODEL_KWARGS[model_name]\n",
    "\n",
    "        if \"action_noise\" in model_kwargs:\n",
    "            n_actions = self.env.action_space.shape[-1]\n",
    "            model_kwargs[\"action_noise\"] = NOISE[model_kwargs[\"action_noise\"]](\n",
    "                mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions)\n",
    "            )\n",
    "        print(model_kwargs)\n",
    "        return MODELS[model_name](\n",
    "            policy=policy,\n",
    "            env=self.env,\n",
    "            tensorboard_log=tensorboard_log,\n",
    "            verbose=verbose,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            seed=seed,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "\n",
    "    def train_model(self, model, tb_log_name, total_timesteps=5000):\n",
    "        model = model.learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            tb_log_name=tb_log_name,\n",
    "            callback=TensorboardCallback(),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def DRL_prediction(model, environment, deterministic=True):\n",
    "        test_env, test_obs = environment.get_sb_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "#         state_memory=[] #add memory pool to store states\n",
    "        test_env.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = model.predict(test_obs, deterministic=deterministic)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "#                 state_memory=test_env.env_method(method_name=\"save_state_memory\") # add current state to state memory\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return account_memory[0], actions_memory[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def DRL_prediction_load_from_file(model_name, environment, cwd, deterministic=True):\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "        try:\n",
    "            # load agent\n",
    "            model = MODELS[model_name].load(cwd)\n",
    "            print(\"Successfully load model\", cwd)\n",
    "        except BaseException:\n",
    "            raise ValueError(\"Fail to load agent!\")\n",
    "\n",
    "        # test on the testing env\n",
    "        state = environment.reset()\n",
    "        episode_returns = []  # the cumulative_return / initial_account\n",
    "        episode_total_assets = [environment.initial_total_asset]\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = model.predict(state, deterministic=deterministic)[0]\n",
    "            state, reward, done, _ = environment.step(action)\n",
    "\n",
    "            total_asset = (\n",
    "                    environment.amount\n",
    "                    + (environment.price_ary[environment.day] * environment.stocks).sum()\n",
    "            )\n",
    "            episode_total_assets.append(total_asset)\n",
    "            episode_return = total_asset / environment.initial_total_asset\n",
    "            episode_returns.append(episode_return)\n",
    "\n",
    "        print(\"episode_return\", episode_return)\n",
    "        print(\"Test Finished!\")\n",
    "        return episode_total_assets\n",
    "\n",
    "\n",
    "class DRLEnsembleAgent:\n",
    "    @staticmethod\n",
    "    def get_model(\n",
    "            model_name,\n",
    "            env,\n",
    "            policy=\"MlpPolicy\",\n",
    "            policy_kwargs=None,\n",
    "            model_kwargs=None,\n",
    "            seed=None,\n",
    "            verbose=1,\n",
    "    ):\n",
    "\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "\n",
    "        if model_kwargs is None:\n",
    "            temp_model_kwargs = MODEL_KWARGS[model_name]\n",
    "        else:\n",
    "            temp_model_kwargs = model_kwargs.copy()\n",
    "\n",
    "        if \"action_noise\" in temp_model_kwargs:\n",
    "            n_actions = env.action_space.shape[-1]\n",
    "            temp_model_kwargs[\"action_noise\"] = NOISE[\n",
    "                temp_model_kwargs[\"action_noise\"]\n",
    "            ](mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "        print(temp_model_kwargs)\n",
    "        return MODELS[model_name](\n",
    "            policy=policy,\n",
    "            env=env,\n",
    "            tensorboard_log=f\"{config.TENSORBOARD_LOG_DIR}/{model_name}\",\n",
    "            verbose=verbose,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            seed=seed,\n",
    "            **temp_model_kwargs,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def train_model(model, model_name, tb_log_name, iter_num, total_timesteps=5000):\n",
    "        model = model.learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            tb_log_name=tb_log_name,\n",
    "            callback=TensorboardCallback(),\n",
    "        )\n",
    "        model.save(\n",
    "            f\"{config.TRAINED_MODEL_DIR}/{model_name.upper()}_{total_timesteps // 1000}k_{iter_num}\"\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def get_validation_sharpe(iteration, model_name):\n",
    "        \"\"\"Calculate Sharpe ratio based on validation results\"\"\"\n",
    "        df_total_value = pd.read_csv(\n",
    "            f\"results/account_value_validation_{model_name}_{iteration}.csv\"\n",
    "        )\n",
    "        # If the agent did not make any transaction \n",
    "        if df_total_value[\"daily_return\"].var()==0:\n",
    "            if df_total_value[\"daily_return\"].mean()>0:\n",
    "                return (np.inf)\n",
    "            else:\n",
    "                return (0.0)\n",
    "        else:\n",
    "            return (\n",
    "                    (4 ** 0.5)\n",
    "                    * df_total_value[\"daily_return\"].mean()\n",
    "                    / df_total_value[\"daily_return\"].std()\n",
    "            )\n",
    "    def __init__(\n",
    "            self,\n",
    "            df,\n",
    "            train_period,\n",
    "            val_test_period,\n",
    "            rebalance_window,\n",
    "            validation_window,\n",
    "            stock_dim,\n",
    "            hmax,\n",
    "            initial_amount,\n",
    "            buy_cost_pct,\n",
    "            sell_cost_pct,\n",
    "            reward_scaling,\n",
    "            state_space,\n",
    "            action_space,\n",
    "            tech_indicator_list,\n",
    "            print_verbosity,\n",
    "    ):\n",
    "\n",
    "        self.df = df\n",
    "        self.train_period = train_period\n",
    "        self.val_test_period = val_test_period\n",
    "\n",
    "        self.unique_trade_date = df[\n",
    "            (df.date > val_test_period[0]) & (df.date <= val_test_period[1])\n",
    "            ].date.unique()\n",
    "        self.rebalance_window = rebalance_window\n",
    "        self.validation_window = validation_window\n",
    "\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.print_verbosity = print_verbosity\n",
    "\n",
    "    def DRL_validation(self, model, test_data, test_env, test_obs):\n",
    "        \"\"\"validation process\"\"\"\n",
    "        for _ in range(len(test_data.index.unique())):\n",
    "            action, _states = model.predict(test_obs)\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "\n",
    "    def DRL_prediction(\n",
    "            self, model, name, last_state, iter_num, turbulence_threshold, initial\n",
    "    ):\n",
    "        \"\"\"make a prediction based on trained model\"\"\"\n",
    "\n",
    "        ## trading env\n",
    "        trade_data = data_split(\n",
    "            self.df,\n",
    "            start=self.unique_trade_date[iter_num - self.rebalance_window],\n",
    "            end=self.unique_trade_date[iter_num],\n",
    "        )\n",
    "        trade_env = DummyVecEnv(\n",
    "            [\n",
    "                lambda: StockTradingEnv(\n",
    "                    trade_data,\n",
    "                    self.stock_dim,\n",
    "                    self.hmax,\n",
    "                    self.initial_amount,\n",
    "                    self.buy_cost_pct,\n",
    "                    self.sell_cost_pct,\n",
    "                    self.reward_scaling,\n",
    "                    self.state_space,\n",
    "                    self.action_space,\n",
    "                    self.tech_indicator_list,\n",
    "                    turbulence_threshold=turbulence_threshold,\n",
    "                    initial=initial,\n",
    "                    previous_state=last_state,\n",
    "                    model_name=name,\n",
    "                    mode=\"trade\",\n",
    "                    iteration=iter_num,\n",
    "                    print_verbosity=self.print_verbosity,\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        trade_obs = trade_env.reset()\n",
    "\n",
    "        for i in range(len(trade_data.index.unique())):\n",
    "            action, _states = model.predict(trade_obs)\n",
    "            trade_obs, rewards, dones, info = trade_env.step(action)\n",
    "            if i == (len(trade_data.index.unique()) - 2):\n",
    "                # print(env_test.render())\n",
    "                last_state = trade_env.render()\n",
    "\n",
    "        df_last_state = pd.DataFrame({\"last_state\": last_state})\n",
    "        df_last_state.to_csv(\n",
    "            f\"results/last_state_{name}_{i}.csv\", index=False\n",
    "        )\n",
    "        return last_state\n",
    "\n",
    "    def run_ensemble_strategy(\n",
    "            self, A2C_model_kwargs, PPO_model_kwargs, DDPG_model_kwargs, timesteps_dict\n",
    "    ):\n",
    "        \"\"\"Ensemble Strategy that combines PPO, A2C and DDPG\"\"\"\n",
    "        print(\"============Start Ensemble Strategy============\")\n",
    "        # for ensemble model, it's necessary to feed the last state\n",
    "        # of the previous model to the current model as the initial state\n",
    "        last_state_ensemble = []\n",
    "\n",
    "        ppo_sharpe_list = []\n",
    "        ddpg_sharpe_list = []\n",
    "        a2c_sharpe_list = []\n",
    "\n",
    "        model_use = []\n",
    "        validation_start_date_list = []\n",
    "        validation_end_date_list = []\n",
    "        iteration_list = []\n",
    "\n",
    "        insample_turbulence = self.df[\n",
    "            (self.df.date < self.train_period[1])\n",
    "            & (self.df.date >= self.train_period[0])\n",
    "            ]\n",
    "        insample_turbulence_threshold = np.quantile(\n",
    "            insample_turbulence.turbulence.values, 0.90\n",
    "        )\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(\n",
    "                self.rebalance_window + self.validation_window,\n",
    "                len(self.unique_trade_date),\n",
    "                self.rebalance_window,\n",
    "        ):\n",
    "            validation_start_date = self.unique_trade_date[\n",
    "                i - self.rebalance_window - self.validation_window\n",
    "                ]\n",
    "            validation_end_date = self.unique_trade_date[i - self.rebalance_window]\n",
    "\n",
    "            validation_start_date_list.append(validation_start_date)\n",
    "            validation_end_date_list.append(validation_end_date)\n",
    "            iteration_list.append(i)\n",
    "\n",
    "            print(\"============================================\")\n",
    "            ## initial state is empty\n",
    "            if i - self.rebalance_window - self.validation_window == 0:\n",
    "                # inital state\n",
    "                initial = True\n",
    "            else:\n",
    "                # previous state\n",
    "                initial = False\n",
    "\n",
    "            # Tuning trubulence index based on historical data\n",
    "            # Turbulence lookback window is one quarter (63 days)\n",
    "            end_date_index = self.df.index[\n",
    "                self.df[\"date\"]\n",
    "                == self.unique_trade_date[\n",
    "                    i - self.rebalance_window - self.validation_window\n",
    "                    ]\n",
    "                ].to_list()[-1]\n",
    "            start_date_index = end_date_index - 63 + 1\n",
    "\n",
    "            historical_turbulence = self.df.iloc[\n",
    "                                    start_date_index: (end_date_index + 1), :\n",
    "                                    ]\n",
    "\n",
    "            historical_turbulence = historical_turbulence.drop_duplicates(\n",
    "                subset=[\"date\"]\n",
    "            )\n",
    "\n",
    "            historical_turbulence_mean = np.mean(\n",
    "                historical_turbulence.turbulence.values\n",
    "            )\n",
    "\n",
    "            # print(historical_turbulence_mean)\n",
    "\n",
    "            if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "                # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "                # then we assume that the current market is volatile,\n",
    "                # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "                # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "                turbulence_threshold = insample_turbulence_threshold\n",
    "            else:\n",
    "                # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "                # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "                turbulence_threshold = np.quantile(\n",
    "                    insample_turbulence.turbulence.values, 1\n",
    "                )\n",
    "\n",
    "            turbulence_threshold = np.quantile(\n",
    "                insample_turbulence.turbulence.values, 0.99\n",
    "            )\n",
    "            print(\"turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "            ############## Environment Setup starts ##############\n",
    "            ## training env\n",
    "            train = data_split(\n",
    "                self.df,\n",
    "                start=self.train_period[0],\n",
    "                end=self.unique_trade_date[\n",
    "                    i - self.rebalance_window - self.validation_window\n",
    "                    ],\n",
    "            )\n",
    "            self.train_env = DummyVecEnv(\n",
    "                [\n",
    "                    lambda: StockTradingEnv(\n",
    "                        train,\n",
    "                        self.stock_dim,\n",
    "                        self.hmax,\n",
    "                        self.initial_amount,\n",
    "                        self.buy_cost_pct,\n",
    "                        self.sell_cost_pct,\n",
    "                        self.reward_scaling,\n",
    "                        self.state_space,\n",
    "                        self.action_space,\n",
    "                        self.tech_indicator_list,\n",
    "                        print_verbosity=self.print_verbosity,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            validation = data_split(\n",
    "                self.df,\n",
    "                start=self.unique_trade_date[\n",
    "                    i - self.rebalance_window - self.validation_window\n",
    "                    ],\n",
    "                end=self.unique_trade_date[i - self.rebalance_window],\n",
    "            )\n",
    "            ############## Environment Setup ends ##############\n",
    "\n",
    "            ############## Training and Validation starts ##############\n",
    "            print(\n",
    "                \"======Model training from: \",\n",
    "                self.train_period[0],\n",
    "                \"to \",\n",
    "                self.unique_trade_date[\n",
    "                    i - self.rebalance_window - self.validation_window\n",
    "                    ],\n",
    "            )\n",
    "            # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
    "            # print(\"==============Model Training===========\")\n",
    "            print(\"======A2C Training========\")\n",
    "            model_a2c = self.get_model(\n",
    "                \"a2c\", self.train_env, policy=\"MlpPolicy\", model_kwargs=A2C_model_kwargs\n",
    "            )\n",
    "            model_a2c = self.train_model(\n",
    "                model_a2c,\n",
    "                \"a2c\",\n",
    "                tb_log_name=f\"a2c_{i}\",\n",
    "                iter_num=i,\n",
    "                total_timesteps=timesteps_dict[\"a2c\"],\n",
    "            )  # 100_000\n",
    "\n",
    "            print(\n",
    "                \"======A2C Validation from: \",\n",
    "                validation_start_date,\n",
    "                \"to \",\n",
    "                validation_end_date,\n",
    "            )\n",
    "            val_env_a2c = DummyVecEnv(\n",
    "                [\n",
    "                    lambda: StockTradingEnv(\n",
    "                        validation,\n",
    "                        self.stock_dim,\n",
    "                        self.hmax,\n",
    "                        self.initial_amount,\n",
    "                        self.buy_cost_pct,\n",
    "                        self.sell_cost_pct,\n",
    "                        self.reward_scaling,\n",
    "                        self.state_space,\n",
    "                        self.action_space,\n",
    "                        self.tech_indicator_list,\n",
    "                        turbulence_threshold=turbulence_threshold,\n",
    "                        iteration=i,\n",
    "                        model_name=\"A2C\",\n",
    "                        mode=\"validation\",\n",
    "                        print_verbosity=self.print_verbosity,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            val_obs_a2c = val_env_a2c.reset()\n",
    "            self.DRL_validation(\n",
    "                model=model_a2c,\n",
    "                test_data=validation,\n",
    "                test_env=val_env_a2c,\n",
    "                test_obs=val_obs_a2c,\n",
    "            )\n",
    "            sharpe_a2c = self.get_validation_sharpe(i, model_name=\"A2C\")\n",
    "            print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "            print(\"======PPO Training========\")\n",
    "            model_ppo = self.get_model(\n",
    "                \"ppo\", self.train_env, policy=\"MlpPolicy\", model_kwargs=PPO_model_kwargs\n",
    "            )\n",
    "            model_ppo = self.train_model(\n",
    "                model_ppo,\n",
    "                \"ppo\",\n",
    "                tb_log_name=f\"ppo_{i}\",\n",
    "                iter_num=i,\n",
    "                total_timesteps=timesteps_dict[\"ppo\"],\n",
    "            )  # 100_000\n",
    "            print(\n",
    "                \"======PPO Validation from: \",\n",
    "                validation_start_date,\n",
    "                \"to \",\n",
    "                validation_end_date,\n",
    "            )\n",
    "            val_env_ppo = DummyVecEnv(\n",
    "                [\n",
    "                    lambda: StockTradingEnv(\n",
    "                        validation,\n",
    "                        self.stock_dim,\n",
    "                        self.hmax,\n",
    "                        self.initial_amount,\n",
    "                        self.buy_cost_pct,\n",
    "                        self.sell_cost_pct,\n",
    "                        self.reward_scaling,\n",
    "                        self.state_space,\n",
    "                        self.action_space,\n",
    "                        self.tech_indicator_list,\n",
    "                        turbulence_threshold=turbulence_threshold,\n",
    "                        iteration=i,\n",
    "                        model_name=\"PPO\",\n",
    "                        mode=\"validation\",\n",
    "                        print_verbosity=self.print_verbosity,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            val_obs_ppo = val_env_ppo.reset()\n",
    "            self.DRL_validation(\n",
    "                model=model_ppo,\n",
    "                test_data=validation,\n",
    "                test_env=val_env_ppo,\n",
    "                test_obs=val_obs_ppo,\n",
    "            )\n",
    "            sharpe_ppo = self.get_validation_sharpe(i, model_name=\"PPO\")\n",
    "            print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "            print(\"======DDPG Training========\")\n",
    "            model_ddpg = self.get_model(\n",
    "                \"ddpg\",\n",
    "                self.train_env,\n",
    "                policy=\"MlpPolicy\",\n",
    "                model_kwargs=DDPG_model_kwargs,\n",
    "            )\n",
    "            model_ddpg = self.train_model(\n",
    "                model_ddpg,\n",
    "                \"ddpg\",\n",
    "                tb_log_name=f\"ddpg_{i}\",\n",
    "                iter_num=i,\n",
    "                total_timesteps=timesteps_dict[\"ddpg\"],\n",
    "            )  # 50_000\n",
    "            print(\n",
    "                \"======DDPG Validation from: \",\n",
    "                validation_start_date,\n",
    "                \"to \",\n",
    "                validation_end_date,\n",
    "            )\n",
    "            val_env_ddpg = DummyVecEnv(\n",
    "                [\n",
    "                    lambda: StockTradingEnv(\n",
    "                        validation,\n",
    "                        self.stock_dim,\n",
    "                        self.hmax,\n",
    "                        self.initial_amount,\n",
    "                        self.buy_cost_pct,\n",
    "                        self.sell_cost_pct,\n",
    "                        self.reward_scaling,\n",
    "                        self.state_space,\n",
    "                        self.action_space,\n",
    "                        self.tech_indicator_list,\n",
    "                        turbulence_threshold=turbulence_threshold,\n",
    "                        iteration=i,\n",
    "                        model_name=\"DDPG\",\n",
    "                        mode=\"validation\",\n",
    "                        print_verbosity=self.print_verbosity,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            val_obs_ddpg = val_env_ddpg.reset()\n",
    "            self.DRL_validation(\n",
    "                model=model_ddpg,\n",
    "                test_data=validation,\n",
    "                test_env=val_env_ddpg,\n",
    "                test_obs=val_obs_ddpg,\n",
    "            )\n",
    "            sharpe_ddpg = self.get_validation_sharpe(i, model_name=\"DDPG\")\n",
    "\n",
    "            ppo_sharpe_list.append(sharpe_ppo)\n",
    "            a2c_sharpe_list.append(sharpe_a2c)\n",
    "            ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "            print(\n",
    "                \"======Best Model Retraining from: \",\n",
    "                self.train_period[0],\n",
    "                \"to \",\n",
    "                self.unique_trade_date[i - self.rebalance_window],\n",
    "            )\n",
    "            # Environment setup for model retraining up to first trade date\n",
    "            # train_full = data_split(self.df, start=self.train_period[0], end=self.unique_trade_date[i - self.rebalance_window])\n",
    "            # self.train_full_env = DummyVecEnv([lambda: StockTradingEnv(train_full,\n",
    "            #                                                    self.stock_dim,\n",
    "            #                                                    self.hmax,\n",
    "            #                                                    self.initial_amount,\n",
    "            #                                                    self.buy_cost_pct,\n",
    "            #                                                    self.sell_cost_pct,\n",
    "            #                                                    self.reward_scaling,\n",
    "            #                                                    self.state_space,\n",
    "            #                                                    self.action_space,\n",
    "            #                                                    self.tech_indicator_list,\n",
    "            #                                                    print_verbosity=self.print_verbosity)])\n",
    "            # Model Selection based on sharpe ratio\n",
    "            if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "                model_use.append(\"PPO\")\n",
    "                model_ensemble = model_ppo\n",
    "\n",
    "                # model_ensemble = self.get_model(\"ppo\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=PPO_model_kwargs)\n",
    "                # model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ppo']) #100_000\n",
    "            elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "                model_use.append(\"A2C\")\n",
    "                model_ensemble = model_a2c\n",
    "\n",
    "                # model_ensemble = self.get_model(\"a2c\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=A2C_model_kwargs)\n",
    "                # model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['a2c']) #100_000\n",
    "            else:\n",
    "                model_use.append(\"DDPG\")\n",
    "                model_ensemble = model_ddpg\n",
    "\n",
    "                # model_ensemble = self.get_model(\"ddpg\",self.train_full_env,policy=\"MlpPolicy\",model_kwargs=DDPG_model_kwargs)\n",
    "                # model_ensemble = self.train_model(model_ensemble, \"ensemble\", tb_log_name=\"ensemble_{}\".format(i), iter_num = i, total_timesteps=timesteps_dict['ddpg']) #50_000\n",
    "\n",
    "            ############## Training and Validation ends ##############\n",
    "\n",
    "            ############## Trading starts ##############\n",
    "            print(\n",
    "                \"======Trading from: \",\n",
    "                self.unique_trade_date[i - self.rebalance_window],\n",
    "                \"to \",\n",
    "                self.unique_trade_date[i],\n",
    "            )\n",
    "            # print(\"Used Model: \", model_ensemble)\n",
    "            last_state_ensemble = self.DRL_prediction(\n",
    "                model=model_ensemble,\n",
    "                name=\"ensemble\",\n",
    "                last_state=last_state_ensemble,\n",
    "                iter_num=i,\n",
    "                turbulence_threshold=turbulence_threshold,\n",
    "                initial=initial,\n",
    "            )\n",
    "            ############## Trading ends ##############\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "        df_summary = pd.DataFrame(\n",
    "            [\n",
    "                iteration_list,\n",
    "                validation_start_date_list,\n",
    "                validation_end_date_list,\n",
    "                model_use,\n",
    "                a2c_sharpe_list,\n",
    "                ppo_sharpe_list,\n",
    "                ddpg_sharpe_list,\n",
    "            ]\n",
    "        ).T\n",
    "        df_summary.columns = [\n",
    "            \"Iter\",\n",
    "            \"Val Start\",\n",
    "            \"Val End\",\n",
    "            \"Model Used\",\n",
    "            \"A2C Sharpe\",\n",
    "            \"PPO Sharpe\",\n",
    "            \"DDPG Sharpe\",\n",
    "        ]\n",
    "\n",
    "        return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e04a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the agent using DRLAgent() class using the environment created in the previous part\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a37d4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41f3f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 109         |\n",
      "|    reward             | -0.00133547 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 10.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -77.1      |\n",
      "|    reward             | 0.07041178 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 33.1       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 17.3         |\n",
      "|    reward             | -0.004141714 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.896        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 130        |\n",
      "|    reward             | 0.91718924 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 9.49       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 52.8      |\n",
      "|    reward             | -2.797189 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.35      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 22.5     |\n",
      "|    reward             | -3.86674 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.768    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -46.1     |\n",
      "|    reward             | 1.3311555 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.11      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 84         |\n",
      "|    reward             | -1.2927682 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.51       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 46            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | 68.2          |\n",
      "|    reward             | -0.0028732123 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 2.75          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 174         |\n",
      "|    reward             | -0.18252929 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 19.3        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -44.3    |\n",
      "|    reward             | 2.565779 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -45.2       |\n",
      "|    reward             | -0.11924325 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | 0.12      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    reward             | 1.2320507 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.596     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -574         |\n",
      "|    reward             | -0.008943005 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 203          |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 77            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.1         |\n",
      "|    explained_variance | 0.0845        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 37            |\n",
      "|    reward             | -0.0032254716 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 1.23          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | -0.191   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    reward             | 3.077072 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.87     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 87         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 0.0783     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -47.1      |\n",
      "|    reward             | 0.16758719 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 27.3       |\n",
      "|    reward             | -4.0644403 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.785      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -164       |\n",
      "|    reward             | -1.8803908 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 24.1       |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 96             |\n",
      "|    iterations         | 2000           |\n",
      "|    time_elapsed       | 103            |\n",
      "|    total_timesteps    | 10000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1999           |\n",
      "|    policy_loss        | -205           |\n",
      "|    reward             | -0.00010916574 |\n",
      "|    std                | 1.02           |\n",
      "|    value_loss         | 25.9           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 191       |\n",
      "|    reward             | 2.8278432 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 19.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -50.9     |\n",
      "|    reward             | 0.3207525 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -33.1     |\n",
      "|    reward             | 1.3324324 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.61      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 124        |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -60        |\n",
      "|    reward             | 0.85735524 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.5        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -60.5    |\n",
      "|    reward             | 0.920858 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -109      |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 7.47      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 140        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -102       |\n",
      "|    reward             | -0.6888891 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.4       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 145           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -40.9         |\n",
      "|    reward             | -0.0011538552 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 1.76          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 1.37e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 195       |\n",
      "|    reward             | 1.8843286 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 26.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.86      |\n",
      "|    reward             | 1.3815249 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.575     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -45.8     |\n",
      "|    reward             | 1.0255988 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 2.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -132     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 172        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -46        |\n",
      "|    reward             | -3.7004187 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.55       |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 95             |\n",
      "|    iterations         | 3400           |\n",
      "|    time_elapsed       | 177            |\n",
      "|    total_timesteps    | 17000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3399           |\n",
      "|    policy_loss        | -338           |\n",
      "|    reward             | -4.5390458e-05 |\n",
      "|    std                | 1.03           |\n",
      "|    value_loss         | 67             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 178       |\n",
      "|    reward             | 7.0467844 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 186         |\n",
      "|    reward             | -0.13237838 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 40.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -68.1     |\n",
      "|    reward             | 1.2216591 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 3.09      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 198           |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | 54.8          |\n",
      "|    reward             | -0.0013513127 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 1.99          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 13.4       |\n",
      "|    reward             | -1.1128235 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.779      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.5        |\n",
      "|    explained_variance | 0.197        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -126         |\n",
      "|    reward             | -0.002300564 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 10.1         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | -0.0334    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 91.3       |\n",
      "|    reward             | -1.8354443 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.63       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 8.96       |\n",
      "|    reward             | 0.65989304 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 1.14       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 839        |\n",
      "|    reward             | -0.6476872 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 383        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 71.9         |\n",
      "|    reward             | -0.001134415 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 4.91         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -112       |\n",
      "|    reward             | -1.9996514 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 11.7       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.7         |\n",
      "|    explained_variance | -0.807        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -32.4         |\n",
      "|    reward             | -0.0025105916 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.8           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 248       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -0.386    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 60.3      |\n",
      "|    reward             | 2.5311077 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 4.53      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 94         |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 2.26       |\n",
      "|    reward             | -0.4914045 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -9.79     |\n",
      "|    reward             | 1.2123762 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 6.26      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 94         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 114        |\n",
      "|    reward             | 0.28677255 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 9.71       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 270           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 609           |\n",
      "|    reward             | -0.0009941607 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 219           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 8.98          |\n",
      "|    reward             | -0.0011126009 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 0.341         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 281       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -94.6     |\n",
      "|    reward             | 2.4334526 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 7.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 287       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 30.2      |\n",
      "|    reward             | 2.1712449 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -55.2     |\n",
      "|    reward             | 1.5728596 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.87      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 297       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 149       |\n",
      "|    reward             | 1.8828373 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 303           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | 39.6          |\n",
      "|    reward             | -6.442143e-05 |\n",
      "|    std                | 1.04          |\n",
      "|    value_loss         | 1.33          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 496       |\n",
      "|    reward             | -8.494041 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 122       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 314       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -96.7     |\n",
      "|    reward             | -1.545914 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.99      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -20.9     |\n",
      "|    reward             | -1.394664 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.757     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -53.6     |\n",
      "|    reward             | 1.0554972 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 2.26      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 6200           |\n",
      "|    time_elapsed       | 330            |\n",
      "|    total_timesteps    | 31000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6199           |\n",
      "|    policy_loss        | 42             |\n",
      "|    reward             | -1.2185418e-05 |\n",
      "|    std                | 1.05           |\n",
      "|    value_loss         | 3.07           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 6300           |\n",
      "|    time_elapsed       | 336            |\n",
      "|    total_timesteps    | 31500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6299           |\n",
      "|    policy_loss        | 124            |\n",
      "|    reward             | -3.7398466e-05 |\n",
      "|    std                | 1.05           |\n",
      "|    value_loss         | 8.43           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 25.6       |\n",
      "|    reward             | 0.24397242 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.783      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.642    |\n",
      "------------------------------------\n",
      "day: 3650, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4948772.60\n",
      "total_reward: 3948772.60\n",
      "total_cost: 17616.43\n",
      "total_trades: 62342\n",
      "Sharpe: 0.775\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 353       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -0.0286   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 132       |\n",
      "|    reward             | 3.7327623 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 15.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 359       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -32.4     |\n",
      "|    reward             | 2.7425768 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.573     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 364       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -8.1      |\n",
      "|    reward             | 0.9511577 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.19      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 6900           |\n",
      "|    time_elapsed       | 370            |\n",
      "|    total_timesteps    | 34500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6899           |\n",
      "|    policy_loss        | 45.5           |\n",
      "|    reward             | -0.00022639261 |\n",
      "|    std                | 1.05           |\n",
      "|    value_loss         | 2.43           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 375        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 68.4       |\n",
      "|    reward             | 0.20368472 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 3.92       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 381       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -77.3     |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.91      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 114         |\n",
      "|    reward             | -0.92816925 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 6.82        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 392       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -314      |\n",
      "|    reward             | -6.495302 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 94.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 398        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -53.8      |\n",
      "|    reward             | -1.1440374 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.57       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 143          |\n",
      "|    reward             | -0.000718017 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 10.4         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 409        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | 69.1       |\n",
      "|    reward             | 0.54342103 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 5.51       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | -22.3         |\n",
      "|    reward             | -0.0012324563 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 0.401         |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 148      |\n",
      "|    reward             | 4.56975  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 18.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 426        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -47.7      |\n",
      "|    reward             | 0.28809002 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.19       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 432       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -177      |\n",
      "|    reward             | 4.3638186 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 14.4      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 437           |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | 27.3          |\n",
      "|    reward             | -0.0010695981 |\n",
      "|    std                | 1.05          |\n",
      "|    value_loss         | 0.899         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 443       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -65.8     |\n",
      "|    reward             | 1.7756947 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.73      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 448           |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | -1.78         |\n",
      "|    reward             | -0.0004074565 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.671         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 454       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 30.3      |\n",
      "|    reward             | 2.1962345 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 460        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -191       |\n",
      "|    reward             | 0.87136686 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 31.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 465       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 32        |\n",
      "|    reward             | -5.883723 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 471      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 220      |\n",
      "|    reward             | 5.215652 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 104      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 476        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | 0.0167     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -76.7      |\n",
      "|    reward             | -0.4903191 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 5.92       |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 8900           |\n",
      "|    time_elapsed       | 482            |\n",
      "|    total_timesteps    | 44500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8899           |\n",
      "|    policy_loss        | -108           |\n",
      "|    reward             | -0.00085268967 |\n",
      "|    std                | 1.06           |\n",
      "|    value_loss         | 7.82           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 487        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | -0.603     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 16         |\n",
      "|    reward             | -1.4984171 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.7        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 492       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -161      |\n",
      "|    reward             | 1.3683448 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 22.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 498       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 196       |\n",
      "|    reward             | -3.383009 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 24.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 503        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 31.1       |\n",
      "|    reward             | -3.3624675 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 508      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 264      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 41.7     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 514          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -44.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 36.6         |\n",
      "|    reward             | -0.003703254 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.869        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 519        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | -0.0137    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 86.3       |\n",
      "|    reward             | 0.57287765 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 7.12       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 524       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -78.3     |\n",
      "|    reward             | 2.5308528 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 6.05      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 529        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 60.9       |\n",
      "|    reward             | 0.31452745 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.15       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 535        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -178       |\n",
      "|    reward             | -1.1466693 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 28.7       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 540           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -404          |\n",
      "|    reward             | -7.493775e-06 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 74.1          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 545       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 226       |\n",
      "|    reward             | 0.3945559 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 30.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 550      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -5.47    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 556       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 20        |\n",
      "|    reward             | -0.309036 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.68      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | -145       |\n",
      "|    reward             | 0.12241399 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 14.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 10500      |\n",
      "|    time_elapsed       | 566        |\n",
      "|    total_timesteps    | 52500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | 68.3       |\n",
      "|    reward             | -2.6657915 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 3.46       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 10600         |\n",
      "|    time_elapsed       | 572           |\n",
      "|    total_timesteps    | 53000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10599         |\n",
      "|    policy_loss        | -97.7         |\n",
      "|    reward             | -0.0021148939 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 6.73          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 577       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | 4.6373973 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 77.2      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 10800          |\n",
      "|    time_elapsed       | 582            |\n",
      "|    total_timesteps    | 54000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 10799          |\n",
      "|    policy_loss        | -242           |\n",
      "|    reward             | -0.00015352317 |\n",
      "|    std                | 1.06           |\n",
      "|    value_loss         | 28.3           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 10900      |\n",
      "|    time_elapsed       | 587        |\n",
      "|    total_timesteps    | 54500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -304       |\n",
      "|    reward             | -3.5163467 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 90.7       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 11000      |\n",
      "|    time_elapsed       | 593        |\n",
      "|    total_timesteps    | 55000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10999      |\n",
      "|    policy_loss        | 48.8       |\n",
      "|    reward             | 0.50470823 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 11100      |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 55500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11099      |\n",
      "|    policy_loss        | 1.47       |\n",
      "|    reward             | -0.1789751 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.104      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 604      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -2.38    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.702    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 609       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -189      |\n",
      "|    reward             | -3.141041 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 22.9      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 11400          |\n",
      "|    time_elapsed       | 614            |\n",
      "|    total_timesteps    | 57000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.3          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 11399          |\n",
      "|    policy_loss        | -9.2           |\n",
      "|    reward             | -3.1474014e-05 |\n",
      "|    std                | 1.06           |\n",
      "|    value_loss         | 5.45           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 620      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -505     |\n",
      "|    reward             | 5.94433  |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 128      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 11600      |\n",
      "|    time_elapsed       | 625        |\n",
      "|    total_timesteps    | 58000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11599      |\n",
      "|    policy_loss        | -24.5      |\n",
      "|    reward             | -1.9197843 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.779      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 11700      |\n",
      "|    time_elapsed       | 630        |\n",
      "|    total_timesteps    | 58500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | -9.54e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11699      |\n",
      "|    policy_loss        | 150        |\n",
      "|    reward             | -2.0655675 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 16.7       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 635      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 26.6     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.499    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 641       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 11.2      |\n",
      "|    reward             | 0.3990453 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.28      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 12000         |\n",
      "|    time_elapsed       | 646           |\n",
      "|    total_timesteps    | 60000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11999         |\n",
      "|    policy_loss        | 1.05          |\n",
      "|    reward             | -0.0012657994 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.163         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 651       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | 0.6199801 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 656         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | -0.827      |\n",
      "|    reward             | -0.76841134 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 5.73        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 661       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 55.3      |\n",
      "|    reward             | 2.1890779 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 666       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -166      |\n",
      "|    reward             | -8.395751 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 48.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 672       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 41.6      |\n",
      "|    reward             | 0.9975761 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 677      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 183      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 682      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -19      |\n",
      "|    reward             | -2.94188 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.435    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 93       |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 687      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | -25.7    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 9.3      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 693        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.5      |\n",
      "|    explained_variance | -0.0124    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | 642        |\n",
      "|    reward             | -10.381696 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 209        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 13000       |\n",
      "|    time_elapsed       | 698         |\n",
      "|    total_timesteps    | 65000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | 24.9        |\n",
      "|    reward             | -0.24752408 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 5.81        |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 13100          |\n",
      "|    time_elapsed       | 704            |\n",
      "|    total_timesteps    | 65500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.6          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 13099          |\n",
      "|    policy_loss        | 49.3           |\n",
      "|    reward             | -1.1487715e-05 |\n",
      "|    std                | 1.07           |\n",
      "|    value_loss         | 33.1           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 13200         |\n",
      "|    time_elapsed       | 709           |\n",
      "|    total_timesteps    | 66000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13199         |\n",
      "|    policy_loss        | 30.9          |\n",
      "|    reward             | -0.0006920738 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.489         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 13300      |\n",
      "|    time_elapsed       | 715        |\n",
      "|    total_timesteps    | 66500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 26.8       |\n",
      "|    reward             | -1.5600137 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.518      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 720        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13399      |\n",
      "|    policy_loss        | 57.2       |\n",
      "|    reward             | -1.0265492 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 5.12       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 13500      |\n",
      "|    time_elapsed       | 726        |\n",
      "|    total_timesteps    | 67500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13499      |\n",
      "|    policy_loss        | 87.3       |\n",
      "|    reward             | -1.7942879 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 4.63       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 731       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 68.2      |\n",
      "|    reward             | 1.872441  |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 11.6     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.0931   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 742       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -40       |\n",
      "|    reward             | 1.4768391 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.44      |\n",
      "-------------------------------------\n",
      "day: 3650, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6114745.10\n",
      "total_reward: 5114745.10\n",
      "total_cost: 9862.80\n",
      "total_trades: 46889\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 13900      |\n",
      "|    time_elapsed       | 748        |\n",
      "|    total_timesteps    | 69500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13899      |\n",
      "|    policy_loss        | 25.1       |\n",
      "|    reward             | -1.8548107 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.633      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 753         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -44.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | 32          |\n",
      "|    reward             | -0.26994017 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 1.28        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 14100      |\n",
      "|    time_elapsed       | 759        |\n",
      "|    total_timesteps    | 70500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14099      |\n",
      "|    policy_loss        | 110        |\n",
      "|    reward             | 0.40150687 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 6.24       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 764       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 65.3      |\n",
      "|    reward             | 1.4823424 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.95      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 14300          |\n",
      "|    time_elapsed       | 770            |\n",
      "|    total_timesteps    | 71500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 14299          |\n",
      "|    policy_loss        | 57.8           |\n",
      "|    reward             | -0.00054006925 |\n",
      "|    std                | 1.08           |\n",
      "|    value_loss         | 3.21           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 775       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 228       |\n",
      "|    reward             | 5.4459367 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 32.8      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 14500         |\n",
      "|    time_elapsed       | 781           |\n",
      "|    total_timesteps    | 72500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14499         |\n",
      "|    policy_loss        | 86.8          |\n",
      "|    reward             | -0.0004776424 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 8.45          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 786       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -1.69e+03 |\n",
      "|    reward             | 5.875514  |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.63e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 792       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 98.4      |\n",
      "|    reward             | -3.149565 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 4.88      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 14800      |\n",
      "|    time_elapsed       | 797        |\n",
      "|    total_timesteps    | 74000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | -170       |\n",
      "|    reward             | -3.1250324 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 22         |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 14900         |\n",
      "|    time_elapsed       | 803           |\n",
      "|    total_timesteps    | 74500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14899         |\n",
      "|    policy_loss        | -86.3         |\n",
      "|    reward             | -0.0010127453 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 3.87          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 808      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 47.6     |\n",
      "|    reward             | 2.063641 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 15100         |\n",
      "|    time_elapsed       | 813           |\n",
      "|    total_timesteps    | 75500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15099         |\n",
      "|    policy_loss        | -9.4          |\n",
      "|    reward             | -0.0021230013 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 1.62          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 819      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 107      |\n",
      "|    reward             | 5.437426 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 6.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 824       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 326       |\n",
      "|    reward             | 3.9307272 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 86.1      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 15400          |\n",
      "|    time_elapsed       | 830            |\n",
      "|    total_timesteps    | 77000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -44.9          |\n",
      "|    explained_variance | 0.126          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15399          |\n",
      "|    policy_loss        | -17.8          |\n",
      "|    reward             | -0.00031148206 |\n",
      "|    std                | 1.08           |\n",
      "|    value_loss         | 1.43           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 835      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -15      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.208    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 841       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -30.7     |\n",
      "|    reward             | -3.248647 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.826     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 846      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 94       |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 5.45     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 15800       |\n",
      "|    time_elapsed       | 852         |\n",
      "|    total_timesteps    | 79000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | 123         |\n",
      "|    reward             | 0.016614703 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 12.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 15900      |\n",
      "|    time_elapsed       | 857        |\n",
      "|    total_timesteps    | 79500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15899      |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | -0.9740917 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 23.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 863        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -726       |\n",
      "|    reward             | 0.33000532 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 272        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 868       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -41.3     |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 874        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | 16         |\n",
      "|    reward             | -0.9931818 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.84       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 879      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -48.8    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 884       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 9.75      |\n",
      "|    reward             | 1.9773849 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 2.51      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 16500      |\n",
      "|    time_elapsed       | 890        |\n",
      "|    total_timesteps    | 82500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -182       |\n",
      "|    reward             | 0.05177958 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 26.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 895        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | -130       |\n",
      "|    reward             | -3.4603872 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 7.96       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 16700       |\n",
      "|    time_elapsed       | 901         |\n",
      "|    total_timesteps    | 83500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 211         |\n",
      "|    reward             | -0.70875233 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 25.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 16800      |\n",
      "|    time_elapsed       | 906        |\n",
      "|    total_timesteps    | 84000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16799      |\n",
      "|    policy_loss        | 66.3       |\n",
      "|    reward             | -2.2986953 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 4.37       |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 16900          |\n",
      "|    time_elapsed       | 912            |\n",
      "|    total_timesteps    | 84500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -45.5          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16899          |\n",
      "|    policy_loss        | -81.4          |\n",
      "|    reward             | -0.00036553477 |\n",
      "|    std                | 1.1            |\n",
      "|    value_loss         | 7.49           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 917       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 111       |\n",
      "|    reward             | 3.4013283 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 6.03      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 17100        |\n",
      "|    time_elapsed       | 923          |\n",
      "|    total_timesteps    | 85500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17099        |\n",
      "|    policy_loss        | 50.5         |\n",
      "|    reward             | -0.008638697 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 2.03         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 928       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -73.3     |\n",
      "|    reward             | 3.1748102 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 933      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -106     |\n",
      "|    reward             | 6.559693 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 8.38     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 17400          |\n",
      "|    time_elapsed       | 939            |\n",
      "|    total_timesteps    | 87000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -45.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17399          |\n",
      "|    policy_loss        | -46.5          |\n",
      "|    reward             | -0.00024947233 |\n",
      "|    std                | 1.11           |\n",
      "|    value_loss         | 1.22           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 17500      |\n",
      "|    time_elapsed       | 944        |\n",
      "|    total_timesteps    | 87500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | 202        |\n",
      "|    reward             | -2.4931421 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 21.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 17600      |\n",
      "|    time_elapsed       | 950        |\n",
      "|    total_timesteps    | 88000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17599      |\n",
      "|    policy_loss        | 7.4        |\n",
      "|    reward             | 0.77041763 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 955       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | -75.5     |\n",
      "|    reward             | 1.8195301 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 4.49      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 17800      |\n",
      "|    time_elapsed       | 961        |\n",
      "|    total_timesteps    | 89000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17799      |\n",
      "|    policy_loss        | 34.6       |\n",
      "|    reward             | -1.6131383 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.832      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 966         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 89.5        |\n",
      "|    reward             | -0.44127557 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 6.23        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 18000         |\n",
      "|    time_elapsed       | 971           |\n",
      "|    total_timesteps    | 90000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.9         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17999         |\n",
      "|    policy_loss        | 103           |\n",
      "|    reward             | -0.0010366327 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 12.5          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 977       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -157      |\n",
      "|    reward             | 1.6222942 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 18200         |\n",
      "|    time_elapsed       | 982           |\n",
      "|    total_timesteps    | 91000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.9         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18199         |\n",
      "|    policy_loss        | -362          |\n",
      "|    reward             | -0.0009625875 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 115           |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 18300      |\n",
      "|    time_elapsed       | 988        |\n",
      "|    total_timesteps    | 91500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18299      |\n",
      "|    policy_loss        | 5.21       |\n",
      "|    reward             | -2.3390124 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.404      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 993         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -45.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 33.3        |\n",
      "|    reward             | -0.14012864 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.93        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 18500        |\n",
      "|    time_elapsed       | 999          |\n",
      "|    total_timesteps    | 92500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -45.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | -86.5        |\n",
      "|    reward             | -0.048576813 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 7.98         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 1004     |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 239      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 35       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 1009      |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 320       |\n",
      "|    reward             | 6.0267715 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 81.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 1015     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -67.5    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 1020      |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -147      |\n",
      "|    reward             | 3.2223384 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 23.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 1026     |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 339      |\n",
      "|    reward             | 2.869366 |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 55.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 1031      |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 98.2      |\n",
      "|    reward             | 1.0766532 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 8.69      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 1037     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -2.69    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.098    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 1042     |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 205      |\n",
      "|    reward             | 4.554585 |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 30.3     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 19400         |\n",
      "|    time_elapsed       | 1047          |\n",
      "|    total_timesteps    | 97000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19399         |\n",
      "|    policy_loss        | -27.3         |\n",
      "|    reward             | -4.077458e-06 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.525         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 1053      |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -665      |\n",
      "|    reward             | -5.588539 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 200       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 1058       |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19599      |\n",
      "|    policy_loss        | 49.4       |\n",
      "|    reward             | -2.9402544 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 3.95       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 1064      |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -2.33e+03 |\n",
      "|    reward             | 24.137114 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 2.91e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 19800        |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 99000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.2        |\n",
      "|    explained_variance | -1.55e-06    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19799        |\n",
      "|    policy_loss        | -36          |\n",
      "|    reward             | -0.000176361 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 1.51         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 1074      |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -83.5     |\n",
      "|    reward             | -1.000102 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 4.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 1080     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | 130      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 17.8     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dd94101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb87007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 3650, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4778453.23\n",
      "total_reward: 3778453.23\n",
      "total_cost: 4709.52\n",
      "total_trades: 63418\n",
      "Sharpe: 0.982\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c17221",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50356b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = data_split(processed_full, '2019-01-01','2021-01-01')\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d188fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = '2019-01-01',\n",
    "        end = '2021-01-01')\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = '2019-01-01',\n",
    "             baseline_end = '2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51a4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cd5af91d",
   "language": "python",
   "display_name": "PyCharm (DatTradeRL)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}